# 并查集(union-find)

## 一、一些在学习此内容所需要的准备

### 1 需要提前了解的知识

​	1、了解链表。

​	2、了解集合的概念。

​	3、知道什么是哈希表

​	4、了解摊还分析中势能法(非必需)

​	4、时间复杂度的计算，以及记号。

​	5、熟悉c或c++的基本语法。

## 二、并查集的定义

​		并查集也叫不相交集合(**disjiont-set**)，是一种非常好用的数据结构，这种数据结构存储不相交的数据集合，在每一个集合中的元素都有着共同的特征，具体取决于如何划分集合。例如我们对整数集$s\in\Z$ ，划分为奇数和偶数并存储在并查集中，那么此时并查集中只有两种不相交集合，分别为$2k+1$的奇数集合和$2k$的整数集合，其中$k\in\Z$ 。

### 1 并查集的性质

​		并查集的精髓体现在“并”这个字上。

​		1、并查集中的每一个集合在划分属性上两两互不相交。

​		2、当我们搜索并查集中的一个元素时，查找到的是其所在的集合名字或者其特有的特征。举个例子，上面奇数偶数组成的并查集我们查询一个元素2时，返回的是**偶数** 也就是其所在的整个集合的特征，因此叫并查。根据这个性质我们可以使用$Find(a)==Find(b)$来判断一个两个元素是否属于同一个集合。	

==示例:==

​		这个例子中显示了由1～8这个几个元素，并且根据$s\space mod\space3$ 的值划分的并查集的抽象表示，其中($mod$代表取模操作，也就是计算$s/3$的余数)。 	

![union-find1](https://tva1.sinaimg.cn/large/e6c9d24egy1h0aoknqvi8j206z05g74f.jpg)

### 2 并查集的基本操作

​		这里要先讲一下并查集的基本操作，主要原因是并查集的基本实现形式有两种，但是其基本操作都是一样

#### 2.1 创建集合(MakeSet)

​		创建集合就是在并查集中加入一个新的集合，在创建新的集合中只含有一个新元素，所以我们$MakeSet$函数为元素的值，我们也可以对其进行扩展，设定一个重载函数接受一个大的集合，这个集合可以是一个数组的形式的参数，我们对这个集合中的每个元素，建立一个子集(因为将要由用户确定划分的模式，可以通过后面介绍的$MergeSet$操作通过合并子集来主动实现划分)。我们期望接受一个参数的$MakeSet$函数能在常数时间内完成，而其重载函数能在$O(n)$ 时间内完成。

#### 2.2 查找(Find)

​		查找操作之前已经大体介绍过了，我们需要$Find$函数就收一个元素，然后返回该元素所在子集的名字或者对应的特征。我们期望能在$O(\lg{n})$的时间内完成查找，当然也有可能达到$O(1)$的时间复杂度。

#### 2.3 合并集合(Union)

​		合并操作需要我们将两个子集合并用以完成划分或其他用途(刚开始是一个元素代表一个子集)。$Union(A,B)$ 表示将两个子集$A$和$B$合并成一个子集，同时这个新子集的名字将发生改变。我们期望在$O(\log{n})$的时间内完成合并的操作。

### 3 并查集的实现方式

​		并查集基本形式有两种实现，还有一种最优化的实现。前两种基本形式为基于数组和基于指针。其中数组实现是最简单的。

### 4 并查集的使用

​		在并查集的大部分应用中，我们的$find$和$Union$都是配合使用，一般使用流程如下面的伪代码所示。

==实现代码:==

```bash
set A = Find(a);
set B = Find(b);
if (A != B)
then
	Union(A,B)
else
	exit;
```

​		我们认为元素$a$和$b$应该在同一个集合中(划分依据发生了变化或其他原因导致)，所以调用$Find()$，检验两个元素是否在同一集合中如果不是，我们将两个集合合并。当然在初始化或添加新元素时时，我们需要调用$makeSet$。

## 三、并查集的数组实现

### 1 实现方式

#### 1.1 简单实现

​		最简单的形式我们可以维护一个数组，然后数组中的每一个空间用来子集的名字。假设整个并查集中有$n$个元素，我们就建立长度为$n$的数组然后加入说要访问第$i$个元素，那我们就访问$array[i-1]$ ，返回它所在的子集的名字。这个在查找方面效率很高，达到了$O(1)$，$MakeSet$也达到了期望的时间复杂度，但是合并集合就不是那么好了，$Union(A,B)$需要$O(n)$的时间，这其中的原因在于我们需要遍历数组，去找到数组所有所在子集为$A$和$B$的位置，并修改他们(因为合并成了一个新的集合，可以沿用两者之间的一个名字，也可以取新名字)。最差情况就是要修改的位置在数组末尾，我们不得不扫描完整个数组，因此为$O(n)$，而且这种实现方式限制了我们只能使用元素在集合中的位置(对应于数组的索引)去访问该元素，而不能使用元素本身的值去访问。这种实现方式像下图所描绘的那样

==示例:==

![union-find2](https://tva1.sinaimg.cn/large/e6c9d24egy1h0asti3cnwj20ch05oglo.jpg)

​		如上图所示，划分为两个子集的数组实现的并查集。

#### 1.2 优化实现

​		我们对上面进行部分优化，使得其合并的时间复杂度下降。我们的进一步优化本质上就是以空间换时间，在之前的基础上，我们使用**对每个子集使用额外的数组**用来记录其所包含的元素在数组中的位置，这样我们就不用遍历整个长度为$n$的数组了去寻找并更新名字了，只需要遍历子集的数组然后根据子集数组中存储的索引去访问大数组，这样效率会高很多。然后我们可以用$Union(A,B)$中$A$和$B$含有较大子集元素数量的名字作为新子集的名字，这样我们只需要更新子集元素较少的子集中元素的名字，进一步减少了开销。新方案实现的并查集如下所示:

==示例:==

![union-find3](https://tva1.sinaimg.cn/large/e6c9d24egy1h0bockniwej20et06j0sz.jpg)

​		在上述实现中，我们的$Find$操作仍然只需要$O(1)$ ，我们的$Union()$操作在经过优化后，假设我们进行$k$次$Union$ ，那么时间复杂度最多$O(k\log{k})$ 。

​		我们下面证明为什么经过$k$次$Union$ 后的时间复杂度为$O(k\log{k})$。

==证明:==我们最后的时间复杂度其实和$k$次操作中更新元素的数目有关，设初始状态为一个元素一个集合，经过$k$次操作，每次操作合并两个集合，每个集合至少一个元素，那么$k$次最多$2k$个元素经过合并操作，假设集合$v$参与了一系列$Union$操作，并且集合$v$每次$Union$都是更新自己子集的元素而不是另外一个(换句话说$v$中自己的元素数量永远比另外一个要少或者相等)，所以每次集合$v$经过$Union$后的大小至少是原来自己的大小的两倍。那么最后$v$的大小最大可能是$2k$ (虽然一般情况下不可能达到$2k$，这个只有$k=1$时才会达到)，因此，集合$v$最多被更新$\log_2{2k}$次，每次更新的元素和$k$成正比，因此最后的时间复杂度为$O(k\log{k})$。最后一句话似乎很难理解，作者当初看$Algorithmn Design$时也不太理解这段话。不过其类似如下图所示

==示例:==

![union-find4](https://tva1.sinaimg.cn/large/e6c9d24egy1h0br98ete9j20cq06r0sw.jpg)

​		

​		我们把合并的过程抽象成一棵二叉树，上述图中，刚开始时有4个集合，每个集合有1个元素，然后各自合并后生成2个含有2个元素的集合。树的高度就是和根结点唯一集合的元素数目的对数有关，同时也是我们上面提到$v$的**最大**更新次数，其中和$v$处在同一层的集合合并的元素个数加上$v$本身合并的元素个数加起来和$k$成正比。所以最后得出了那个复杂度。本人是这么理解的，如果有人有更好的理解(可以参考算法设计英文版的153页)，欢迎指正，但正如上面那段话中提到的，只有k=1时根结点的元素数量才能达到$2k$。

### 2 MakeSet

​		在证实讲述这个操作实现之前，我们先要考虑如何具体实现数组实现的并查集，由于并查集的数组实现存在着诸多限制，首先我们只能通过索引去访问数组从而获取元素所在的集合的名字，所以对于这种实现的并查集来说，不用关心元素值的大小，而是应该关心元素在数组中的索引。所以我们的$MakeSet$时，接受元素值这个参数是没有意义的。我们需要用户自己将元素值和其在数组中的索引对应起来，因此这种实现的$MakeSet$应该是无参数的或者接受一个需要创建集合数量的参数(重载函数)，当使用$MakeSet$时新集合中的元素所对应的索引就是建立前数组的大小。(这里特指无参数的，有参数，假设有n个新元素的新集合，那么其中每个元素的索引为建立前数组的大小依次加1)。然后用户应当自己把元素值和索引值关联，方便之后的查找。最后我们约定集合的名字为创建时整个并查集中所拥有集合的数量+1。

​		有了以上的考虑，我们先给出集合的实现。

==实现代码:==

```c++
struct Set
{
    Set(int k):name(k){}
    std::vector<int> array;//用于存储其中元素在大数组中的索引。
    int name;//代表集合的名字。
};
```

​		里面有一个存放其集合中的元素在数组索引位置的数组。

​	其次，我们在给出并查集的ADT实现的声明，如下。

==实现代码:==

```c++
class DisjointSet
{
public:
    DisjointSet();//构造函数
    ~DisjointSet();//析构函数
public:
    void makeSet();//建立一个新集合
    void makeSet(int n);//建立n个新新集合
    int find(int i);//输入待查询元素在数组中的编号来获取其所在的集合名字
    void Union(int a, int b);//合并操作
private:
    std::vector<int> _array;//大小为元素的数目，里面存放和每个元素所在集合的名字
    std::vector<Set> _setList;//用于存放集合，我们可以通过集合的名字快速找到这个集合。
};
```

​		在这之中，我们使用标准库中的$vector$来实现元素所在集合的存放和集合的存放，集合的名字实质上就是其在$\_setList$中的位置。

​		有了以上的铺垫。我们$MakeSet$操作两种实现方式如下:

```c++
void DisJointSet::makeSet()
{
    int k = _setList.size();//获取荡子集合的数量作为名字
    _setList.emplace_back(Set(k));//加入子集合数组
    _setList[k].array.push_back(_array.size());//添加新元素在数组中的索引
    _array.push_back(k);//添加新元素对应的集合。
}
void DisjointSet::makeSet(int n)
{
    int k = _setList.size();
    //连续创建n个集合
    for (size_t i = 0; i < n; i++)
    {
        _setList.emplace_back(Set(k + i));
        _setList[k + i].array.push_back(_array.size);
        _array.push_back(k + i);
    }
}
```

==时间复杂度:== $O(1)$和$O(n)$。

### 3 Find

​		$Find$操作的实现非常简单，我们只需要根据索引访问数组即可。

==实现代码:==

```c++
int DisjointSet::find(int i)
{
    if(i >= _array.size() || i < 0)//待查找的索引超出范围
    {
        return -1;//返回-1
    }
    return _array[i];
}
```

==时间复杂度:== $O(1)$。

### 4 Union

​		Union操作我们只需要通过集合中存储好的元素在数组中的索引，然后通过索引去访问数组并修改其所在集合名即可(我们只需要修改待合并两个集合中元素较少的那个集合)。

==实现代码:==

```c++
void DisJointSet::Union(int a, int b)//将两个名字为a和b的集合合并
{
    if (a >= _setList.size() || a < 0 || b >= _setList.size() || b < 0)
    {
        throw std::invalid_argument(" a and b should be < total number of set and > 0");
    }
    //如果集合a中的元素较多，那我们就讲集合b中的元素所在集合的名字更新为a
    if(_setList[a].array.size() > _setList[b].array.size())
    {
        for(auto i = _setList[b].array.begin(); i != _setList[b].array.end(); i++)
        {
            _array[*i] = a;//名字更改为a。
        }
    }
    else
    {
        for(auto i = _setList[a].array.begin(); i != _setList[a].array.end(); i++)
        {
            _array[*i] = b;//名字更改为b。
        }
    }
}
```

​		我们注意到，按照道理来说，合并后另一个集合应该从集合列表中剔除，但我们并没有这样做，原因是集合的名字就是其在列表中的索引位置，如果使用erase，将会导致，后面的集合往前移，其名字就发生了变化，因此的花费大量时间更改，得不偿失。这样做会硬气空间上的浪费。更好的做法是用链表存储每个集合，然后$\_array$ 中存放指向元素所在的集合的链表结点。这样做会非常好，因为集合的名字只和其所在的地址有关($\_array$存放的是指针，也就是地址)，和其在链表中的索引位置无关，所以可以在链表中删除结点。值得注意的是，我们需要将其存储为双向链表，这样可以将$erase()$的时间复杂度降到$O(1)$(接受指针作为参数的$erase$) 具体实现，留给读者。

## 四、并查集的指针实现

### 1 实现方式

​		另一种实现是使用指针，集合中的所有元素都含有一个指向其所在集合名字的指针，我们可以在集合中选取一个代表性的元素，然后其他和其所在同一个集合的元素的指针都指向它，代表元素的指针可以指向其自己后者为空，它的实现类似如下。

==示例:==

![union-find5](https://tva1.sinaimg.cn/large/e6c9d24egy1h0cuekt75oj20bz06mt8s.jpg)

​		这一种实现导致了其合并效率非常高。为$O(1)$，因为当两个集合合并时，我们只需将其中一个集合的代表元素的指针指向另外一个集合的代表元素即可，这种实现只需要$O(1)$的时间复杂度，就想下面表示的那样，为上面两个集合合并。

==示例:==

![union-find6](https://tva1.sinaimg.cn/large/e6c9d24egy1h0cv15ae4oj205p02z0sl.jpg)



​		但是，简洁的合并操作也带来了其他的代价，我们的$Find$ 操作不能在常数时间内完成了。我们需要顺着元素的指针，一直访问到其代表元素所在的结点，才能知道自己所在的集合。因此，查找一个元素所在的集合所需的次数取决于其从最开始所在的集合开始(也就是集合的代表元素就是其自己)，其集合的名字经历了多少次更新(这是因为每次更新，都会使其所在的集合增加一个父结点)。集合名字的更新只在合并时产生。所以如果我们在合并操作时不按照合理的方式合并的话，会造成$Find$时间复杂度为$O(n)$ 。

​		所以我们每次$Union$时还是要做一些小调整，我定义一个结点的==秩(rank)==为**该结点的深度**，类似于树，只不过这棵树是反的。作为新集合的名字。因此，我们得额外维护每个结点的秩。每次$Union$我们将秩较小的代表元素连接秩较大的代表元素。

​		下面我们证明经过改进后的$Find$操作的时间复杂度为$O(\lg{n})$ 。

==证明:==

​		我们假设带查找的元素为$v$，我们每次合并按照上面的说法，将集合中含有元素数量较小的代表元素的指针指向另外一个集合的代表元素。我们从最初状态开始(一个集合一个元素)，假设每次合并$v$所在的集合代表元素的秩和预期合并的集合代表元素的秩相同，然后$v$所在的代表元素连接另一个集合的代表元素，所以其每次合并后对$v$的查找，查找遍历的结点数都要增加1(我们计算最糟糕的情况)，合并后元素$v$所在的集合的高度为$O(\log_2{l})$（每次合并都是一个二叉树虽然我们不能确定其是否是满的，但我们可以用$O()$去估计以去除细节） ，其中$l$为该集合中元素的数量，而集合中最多$n$个元素并且在最后$v$所在的集合大小不超过$n$(总共的元素个数)。所以从最开始到最后，查找$v$最糟糕的情况就是$v$是这棵树的叶结点。所以查找$v$所在集合时间复杂度为$O(\lg{n})$。

### 2 结点的定义

​		我们需要将元素和一个指针关联，同时我们希望能在结点的定义中维护元素所在集合的大小，这样我们就不用额外建立一个数据结构中去维护了，因此，我们的结点定义像下面代码定义的那样。

==实现代码:==

```c++
struct Node
{
    Node(int k):key(k),rank(0),parent(nullptr){}//构造函数
    int key;//元素值
    int rank;//记录结点的秩
    Node* parent;//指向父结点的指针
};
```

​		$key$和$parent$这两个变量没什么好说的，至于$size$的定义可能会有点模糊，我们那下面的图举例:

==示例:==

![union-find7](https://tva1.sinaimg.cn/large/e6c9d24egy1h0cx8mhdf0j205404s0sl.jpg)

​		

​		其中3和5的$size$为1，1的$size$为3，2的$size$为4，我们可以看到这中$size$的定义和树中结点或子结点为根的树的所含有元素个数相同，只不过这棵树的指针是反向的。

​		这样做以后我们就能轻松维护集合中所含元素的数量了，我们只需要访问其代表元素的$size$即可。当我们合并式，我们只需要将其中一个代表元素的$size$加上另外一个代表元素的$size$ 即可计算新集合的元素数量大小。

### 3 MakeSet

​		再介绍$MakeSet$的操作之前，我们先介绍其ADT声明，具体如下:

==实现代码:==

```c++
class DisjointSet
{
public:
    DisjointSet();//构造函数
    ~DisjointSet();//析构函数
public:
    void makeSet(int a);//建立一个新集合，参数为这个集合的初始元素值
    void makeSet(const vector<int> & a);//为n个元素建立n个集合
    Node* find(int i);//输入待查询元素在数组中的编号来获取其所在的集合名字
    void Union(Node* a, Node* b);//合并操作
private:
    std::unordered_map<int, Node*> HashTable;//存放元素的hash表
};
#endif
```

​		注意到，我们使用了标准库的$std::unordered\_map$来存储元素和结点的对，这个是一张哈希表，需要包含头文件$\#include<unordered\_map>$ ，这么做的原因是，我们在可以根据$find$函数参数中给定的元素值，快速找到其对应的结点，然后再通过结点访问到其代表元素所在的结点。我们的并查集不支持重复的元素，想要支持可以使用$std::mutiunordered\_map$,我们的$Union$接受两$Node*$类型的参数，用户需要根据$find()$返回的$Node*$然后调用这个函数，这是我们在之提到的并查集的使用时候的要求。

​		下面正式实现两种类型的$MakeSet$。

==实现代码:==

```c++
void DisjointSet::makeSet(int a)
{
    Node* newNode = new Node(a);
    HashTable.insert({a, newNode});
}
void DisjointSet::makeSet(const std::vector<int> & a)
{
    for (auto i = a.begin(); i != a.end(); i++)
    {
        Node* newNode = new Node(*i);
        HashTable.insert({*i, newNode});
    }
}
```

==时间复杂度:==$O(1)$和$O(n)$。

### 3 Find

​		我们首先需要从哈希表中找到该元素对应的结点，然后通过结点的$parent$访问到该结点所在集合的代表元素，返回代表元素。	

==实现代码:==

```c++
Node* DisjointSet::find(int i)
{
    auto result = HashTable.find(i);//获取查找结果
    if (result == HashTable.end())//如果集合中未含此元素，返回空指针。
    {
        return nullptr;
    }
    Node* targetNode = result->second;//获得元素对应的Node
    while(targetNode->parent != nullptr)//寻找到期代表元素。
    {
        targetNode = targetNode->parent;
    }
    return targetNode;//返回代表元素
}
```

==时间复杂度:== $O(m\log{n})$。

### 4 Union

​		比较简单，直接给出代码，不在阐述。

==实现代码:==

```c++
void Union(Node* a, Node* b)
{
    if (a == nullptr || b == nullptr)
    {
        throw std::invalid_argument("argument can't be nullptr");
    }
    if (a->size > b->size)//取集合中含有元素较多的集合的代表元素作为新集合的代表元素
    {
        b->parent = a; 
        a->rank = std::max(b->rank + 1 , a->rank);
    }
    else
    {
        a->parent = b;
        b->rank = std::max(a->rank + 1, b->rank);
    }
}
```

==时间复杂度:==$O(1)$。

## 五、指针实现形式的进一步优化

### 1 去除多余遍历(路径压缩优化)	

​		其实我们的指针形式还有优化的空间，它的最终优化了连续调用$Find$时的操作时间。要理解这个优化我们需要理解这样一个事实，在我们$Find$一个元素所在集合的代表元素时，我们途中路过的所有结点其实都在这个集合中，如果我们后序的查找查找到了这些结点，那么这种查找中的再一次遍历路径是多余的，因为在前面的查找中，我们就已经确认了其已经属于这个集合了。所以我们的优化是，在单次遍历完路径找到其代表元素时，我们需要返回原来$find$参数所在的结点，然后再遍历一次，并将所有路径上的结点的$Parent$指针指向其代表元素的结点。这样当我们第二次调用$Find$访问这些结点的时候，只需要$O(1)$。虽然对于某些结点的查找，开销增加了(因为要多遍历一次)，但是对于大多数结点，他们的查询速度有了质的提升。具体过程就像下图那样。

==示例:==

![union-find8](https://tva1.sinaimg.cn/large/e6c9d24egy1h0d0lelk9tj20hn09cjrn.jpg)

​		

​		因此，我们只需要对$Find$的代码稍微做一下修改即可，具体不在给出，读者自行完成。

### 2 优化后的开销(拓展)

​		这部分内容需要额外的知识，我们将证明经过上述优化后，$Find$操作运行时间为$O(\alpha(n))$ ，其中$\alpha(n)$为一个增长速度极慢的反阿克曼函数($inverse Ackermann function$，不是进击的巨人中的阿克曼家族！)。而对于含有$m$个集合的并查集操作的运行时间为$O(m\alpha(n))$。

​		你首先得了解阿克曼函数，阿克曼函数是一个随输入参数增大，结果增大极快的函数。而反阿克曼函数就是其反函数，因此其增长速度极慢，另外阿克曼函数有多种形式。

​		注意以下证明参考了《算法导论》21.4，只是给出了简单的证明。

​		首先我们定义函数$A_k(j)$为:
$$
A_k(j)=\begin{cases}
j+ 1 &k=0\\
\small A_{k-1}^{j+1}(j) &k\ge1
\end{cases}
$$
​		其中$A_{k-1}^{j+1}(j)$ 中对于上标$j+1$的含义是对同一个值，该函数作用于这个值$j+1$次，比如一个函数$f(n)=2n$，那么$f^{3}(n)=2(2(2n))=2^3n$ ，也可以理解为函数对同一个值的嵌套次数。 这种称为==多重函数==，像这种多重函数具体数学定义如下:
$$
f^i(n)=\begin{cases}
n&i=0\\
f(f^{i-1}(n))&i\ge1
\end{cases}
$$
​		回到之前的函数定义，下标$k$表示函数$A$的级。由此可知，函数$A_k(j)$随着$j$和$k$严格递增。

​		我们先试着计算$A_1(j)$和$A_2(j)$ 。

​		$A_{1}(j)$非常好计算，只需要递归代入多重函数的定义，以及$A_{0}(j)$的表达式即可，我们可以得到$A_{1}^{j+1}(j)=A_0^{j+1}(j)$ ，然后代入多重函数的定义得到$A_{0}^{j+1}(j)=((\dots(j+1)+1)+1\dots+1)$ ，其中总共有$j+1$ 个1，所以结果为$A_{1}(j)=2j+1$。

​		$A_{2}(j)$略微难算一点，首先代入函数定义得出$A_2(j)=A_{1}^{j+1}(j)$。在上一步中，我们已经求出了$A_1(j)$的函数表达式，因此，我们仍然按照多重函数的定义递归代入得到$A_{2}(j)=(2(2(2\dots2(2j+1)+1)+1\dots)+1)=2^{j+1}(j+1)-1$ 。我们可以看到，在$k=1$时还是线性级的变化，到了2时就已经是指数级的变化了，变化非常的快。我们按照以上的形式，有兴趣的话可以计算$A_{4}(1)$，结果近似为$16^{512}$次方。

​		下面我们定义其反函数，对于整数$n\ge0$，$\alpha(n)$定义如下:		
$$
\alpha(n)=\min\{{k:A_{k}\ge n}\}
$$
​		上述定义表示，$\alpha(n)$是满足$A_k(1)$至少为$n$的最小级别$k$。$A_{4}(1)$的结果已经是一个天文数字了，因此实际中$\alpha(n)\le4$。

​		我们之前定义了==秩==，由于该时间复杂度，是经过==秩==和==路经压缩==优化后的结果，所以我们先来看秩的一些简单性质。

==引理1:==对于所有结点$x$，有$x.rank < x.parent.rank$ 。当$x\neq x.parent$时，$x.rank$的值在后序的合并中就再也不会发生变化了。

==证明:==这个非常好证，我们只需观察我们$Union$操作的实现方式即可。每次$Union$时其中一个结点的代表元素是另一个代表元素的==秩==加1或者是本身，我们设另一个代表元素为$x$。我们从最开始每个结点一个集合开始合并，不能成为新集合代表元素的结点都是$x$，都满足不等式，其次在这之后，不是集合代表元素的结点都不会再发生变化，因为每次$Union$都是针对集合代表元素的操作。

​		有上述引理我们得出推论:

==推论1:==从任何一个结点指向其代表元素的简单路径上，结点的秩是严格递增的。

​		虽然在四中已经证明了$Find()$操作的时间复杂度为$O(\lg{n})$，换句话说，一个结点的秩最大为$\lfloor\lg{n}\rfloor$ 。但我们仍然可以取义个较弱的界，以方便我们后序的证明，我们设每个结点最大的秩为$n-1$。	

​		下面我们将利用摊还分析中的势方法证明$O(m\alpha(n))$的时间界。

==引理2:==我们将$Union$操作转换为两个$Find$操作然后再接一个$Link$(连接操作，两个代表元素连接)(这么做的原因是我们Union参数接收的是代表元素所在的结点，所以要先Find)，于是对于$m$个$MakeSet、Union、Find$操作序列转换为$m$个$MakeSet、Link、Find$操作序列，如果后一个运行时间为$O(m\alpha(n))$，那么前一个运行时间为$O(m'\alpha(n))$。

==证明:==这个非常好证，以为转换是线性成比例的转换(1:3)，所以我们有$m=O(m')$，所以自然有$O(m'\alpha(n))$。

​		因此有了这个引理，我们只需证明转换后的$m$个序列操作的时间复杂度为$O(m\alpha(n))$ ,那么原序列也自然成立。

​		假设在经过$q$个操作之后，我们对每个结点定义势函数为$\phi_{q}(x)$ ，那么整个并查集的势为${\psi_{q}}=\displaystyle\sum_{x}\phi_{q}({x})$。第一次操作之前并查集为空，$\psi_{i}=0$。其中$\phi_{q}(x)$取决于在$q$次操作后，$x$是否是代表元素，如果是，那么我们定义其为$\alpha(n)*x.rank$。

​		对于不是代表元素的结点，我们定义一个辅助函数:
$$
level(x)=\max\{k:x.p.rank\ge A_{k}(x.rank)\}
$$
​		上述等式其实定义了$x$在$A_k$函数上的最大级，因此可以推出$0< level(x)<\alpha(n)$ 。而$x.parent.rank>x.rank=A_{0}(x.rank)>0$， 于是$level(x)>0$ 。其次有:
$$
\begin{split}
A_{\alpha(n)}(x.rank)\ge& \space A_{\alpha(n)}(1)&(严格递增)\\
\ge&\space n&\space\qquad\qquad\qquad(根据\alpha(n)的定义)\\
>&x.p.rank&(一个结点的最大秩为n-1)
\end{split}
$$
​		于是可以得到$level(x)<\alpha(n)$。

​		然后定义第二个辅助函数:
$$
iter(x)=\max{i:x.p.rank\ge A_{level(x)}^{(i)}(x.rank)}
$$
​		也就是说，$iter(x)$是可以迭代地实施$A_{level(x)}$的最大次数。

​		当$x.rank>1$时，我们有
$$
1\le iter(x)\le x.rank
$$
​		它可以由如下推出:
$$
\begin{split}
x.p.rank\ge&A_{level(x)}(x.rank)&\qquad(level(x)的定义)\\
=&A_{level(x)}^1(x.rank)
\end{split}
$$
​		这表明$iter(x)\ge1$。

​		其次，由:
$$
\begin{split}
A_{level(x)}^{(x.rank+1)}(x.rank)=&A_{level(x)+1}(x.rank)&\qquad(A_{k}(j)的定义)\\
>&x.p.rank&(level(x)的定义)
\end{split}
$$
​		我们得到$iter(x)\le x.rank$。

​		现在正式定义势函数:
$$
\phi_q(x)=\begin{cases}
\alpha(n)*x.rank&如果x为其所在集合的代表元素\\
(\alpha(n)-level(x))*x.rank-iter(x)&如果x不是其所在集合的代表元素
\end{cases}
$$
==引理3:==对于每个结点$x$和操作数$q$，我们有:
$$
0\le\phi_{q}\le\alpha(n)*x.rank
$$
==证明:==首先对于代表元素所在结点的$\phi_{q}$的定义，这个结论是自然成立的。然后对于非代表元素。我们可以根据之前的结论得出，对于其下界，应该使得$level(x)$尽可能的大，然后$iter(x)$尽可能的大。于是我们由$level(x)<\alpha(n)\equiv level(x)\le(\alpha(n)-1)$（$level(x)$为整数）以及$iter(x)\le x.rank$ 可以推出:
$$
\phi_q(x)\ge(\alpha(n)-\alpha(n)+1)*x.rank-x.rank=0
$$
​		同样的，对于其上界，我们取$level(x)$和$iter(x)$的最小值。由$level(x)>0$以及$iter(x)\ge 1$得:
$$
\phi_q(x)\le\alpha(n)*x.rank-1<\alpha(n)*x.rank
$$
​		综上，得证，同时我们也可以得出，非代表元素所在结点的$\phi_{q}(x)<\alpha(n)*x.rank$。

==引理4:==设$x$是一个非代表元素所在的结点，并且假设第$q$个操作是$Link$和$Find$，那么在第$q$个操作之后，$\phi_{q}(x)\le\phi_{q-1}(x)$。其次，如果$x.rank\ge1$，并且$level(x)$和$iter(x)$在操作$q$之后发生了变化，那么$\phi_{q}(x)\le\phi_{q-1}(x)-1$，也就是说非根结点的势是不可能增加的。

==证明:==由于$x$不是一个代表元素所在的结点，所以$x$的秩不会增加，所以$\phi_{q}(x)-\phi_{q-1}(x)$的$x.rank$项会被消去，然后，对于$\alpha(n)$，由于我们已经建立好了$n$个元素组成的并查集了，$n$不发生变化，所以$\alpha(n)$不发生变化。所以这一项也会被消去。下面分析$level(x)$和$iter(x)$。当操作$q$并未引起$level(x)$的变化时，由$iter(x)$的定义，我们可以知道，$iter(x)$或者增加或者不变，(注意，这里的增加是因为$x.p.rank$增加而导致的)。不变时，$\phi_{q}(x)=\phi_{q-1}(x)$，增加时$\phi_{q}(x)<\phi_{q-1}(x)$，并且由于其至少增加1($iter(x)$为整数)，所以$\phi_{q}(x)\le\phi_{q-1}(x)-1$。由于$level(x)$是单调递增的(这是因为$x.p.rank$是递增的)，所以$level(x)$增加时，$level(x)$至少增加1。根据$iter(x)$的定义，$level(x)$的增加，必然会导致$iter(x)$的减小。而$iter(x)$最多减少$x.rank-1$（根据其范围）。所以根据$\phi_q{(x)}=(\alpha(n)-level(x))*x.rank-iter(x)$，其至少减小1$iter(x)$的减小导致的势能增加并不能大于$level(x)$增大引起的势能减小。综上，得证。

​		下面说明$MakeSet$的摊还代价为$O(1)$$Link、Find$操作的摊还代价都是$O(\alpha(n))$.

==引理5:==每个$MakeSet$操作的摊还代价为$O(1)$。

==证明:==创建结点时结点的秩为0，$\phi_q(x)=0$，根据$\hat{c_{i}}=c_{i}+\psi_{(q)}-\psi_{(q-1)}$，可以计算得出$Makeset$的摊还代价为$O(1)$。

==引理6:== 每个$Link$操作的摊还代价为$O(\alpha(n))$。

==证明:==$Link$操作的实际成本为$O(1)$，假设待连接的两个结点为$x$和$y$，并且连接后$y$为$x$的父结点，我们注意到势能的改变只涉及$x、y$和$y$的子结点。根据引理4，$y$的子结点的势能并不会因为$Link$操作而增加。其次再看$x$，$x$在$Link$操作之前为根结点，所以根据定义$\phi_{q-1}(x)=\alpha(n)*x.rank$。之后$x$变为非代表元素所在的结点。所以有$\phi_{q}(x)<\alpha(n)*x.rank=\phi_{q-1}$。所以$x$的势能减小了。对于$y$，操作前为根结点$\phi_{i-1}=\alpha(n)*x.rank$，操作后仍为根结点，其秩不变或增加1，所以最终结果为最多增加$\alpha(n)$。所以最后的摊还代价为势能增加的部分加上实际的操作时间为$O(1)+O(\alpha(n))=O(\alpha(n))$。

==引理7:==每个$Find$操作的摊还代价为$O(\alpha(n))$。

 ==证明:==设$Find$操作的实际成本为$O(s)$，其中$s$为路径长度。首先证明没有结点的势能会增加，除了根结点，对所有的非代表元素结点使用引理4，都能说明其势能没有增加，除此之外，由于$find$操作并没有增加结点的秩，因此根据代表与阿苏所在结点的势函数的定义，其势能并没有增加。

​		接着，我们证明路径上至少有$\max(0,s-\alpha(n)-2)$的结点的势能至少减少1。假设$x$是查找路径上一个满足$x.rank>0$的结点，且在查找路径上的某处，$x$后跟每个非代表元素所在的结点$y$，它在$Find$操作之前有$level(x)=level(y)$，在查找路径上，除了至多$\alpha(n)+2$个结点外，其他所有结点都满足关于$x$的限制，，不满足限制的包括查找路径上第一个结点和最后一个结点，和路径上最后一满足$level(w)=k$的结点。

​		接着我们固定这样的$x$，假设$k=level(x)=level(y)$ ，在$Find$操作之前，我们有:
$$
\begin{split}
x.p.rank\ge& A_{k}^{iter(x)}(x.rank)&\qquad(根据iter(x)的定义)\\
y.p.rank\ge&A_k(y.rank)&(根据level(y)的定义)\\
y.rank\ge& x.p.rank&(y在x的后面)
\end{split}
$$
​		上述不等式组合在一起，假设路径压缩前$iter(x)$的值为$i$,我们有:
$$
\begin{split}
y.p.rank\ge& A_k(y.rank)\\
\ge&A_k(x.p.rank)\\
\ge&A_{k}(A_{k}^{iter(x)}(x.rank))
=&A_{k}^{i+1}(x.rank)
\end{split}
$$
​		因为路经压缩将使得$x$和$y$有相同的父结点，那么在路经压缩之后$x.p.rank=y.p.rank$，并且压缩路径不减少$y.p.rank$ ，因为$x.rank$未改变，在路径压缩之后就有$x.p.rank\ge A_{k}^{(i+1)}(x.rank)$ 。因此，路径压缩将时$iter(x)$增加或$level(x)$增加，不管是哪种情况，根据引理4，其势能至少减少1.由于势能至少下降了$max(0,s-(a(n)+2))$，因此摊还代价为$O(s)-(s-(\alpha(n)+2))=O(\alpha(n))$。

==定理1:==综合引理2、5、6、7，我们可以得到$m$个操作序列(包含基本的三个操作)，在最坏情况下的运行时间为$O(m\alpha(n))$。

​		以上只是较为简单的证明，实质上还是有很多困惑的地方，比如说如何选取势函数，或者是最开始的阿克曼函数是如何得出的，更加具体的论证可以参考[tarjan的论文](https://e-maxx.ru/bookz/files/dsu/Worst-Case%20Analysis%20of%20Set%20Union%20Algorithms.%20Tarjan,%20Leeuwen.pdf)。

## 六、使用场景

​		最小生成树算法中的Kruskal's Algorithm中的核心数据结构，同时也有其衍生的聚类算法的核心数据结构。

## 七、如有错误或描述不当，请多多指教！不胜感激！

  ![2806a6a5468dd406bb47c5787c3fea88](https://tva1.sinaimg.cn/large/e6c9d24egy1h0g1d12i8sj20u00u0q5p.jpg)																																																				

​																																																										             																																															2022年 1月4日                                                                                               	                  				                                                   																										weekie_OUO
