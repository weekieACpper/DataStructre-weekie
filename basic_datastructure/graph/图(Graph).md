# 图(Graph)

## 一、一些学习此内容所需要的准备

### 1 需要提前了解的知识	

​		1、熟悉链表。

​		2、了解矩阵。

​		3、熟悉树及树的遍历。

​		4、时间复杂度的计算，以及记号。

​		5、熟悉c或c++的基本语法。

### 2 一些命名上的约定

​		这里将用大些字母$G$表示图，对于给定图$G=(V,E)$ ，$|V|$代表图中的==结点数==，而$|E|$代表图中==边的条数==，其次如果在时间记号中出现$V$或$E$，例如$O(VE)$，那么其就代表$O(|V||E|)$。我们使用$G.V$代表图的结点集，$G.E$代表边集。如果图中存在两点$u,v\in G.V$，在无向图中，我们可以用$(u,v)$代表连接两点的边(如果两点之间有边的话)。在有向图中，我们应该根据边方向书写，例如这条边由$v$指向$u$，那我们用$(v,u)$表示它，

## 二、图的定义

​		图的定义其实比树还要一般化，在离散数学中图论的内容在大多数教科书中是安排在树的前面的。图包含了一个有限集合中的==点==，以及连接点与点的==边==的集合。这是一般图的最基本的定义，我们可以看到其实树就是图的一种特殊化情况。图很像我们现实生活中的交通路网。下面我们将介绍两种类型的图，以及图的基本表示方法。

### 1 无向图

​		在无向图中，点与点之间是没有固定的顺序的，也就是说点与点之间是平等，连接各个点的的边没有方向性(没有箭头，没方向)，下图是它的一个例子:

==示例:==

![Graph1](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pb0nlmg8j208004cgli.jpg)

​		

​		上图中，结点上的数字是编号，它可以是任意的。作为和待会有向图的对比，我们其实可以把无向图中的边看成像交通路当中的双向通行道。也就是说我们可以从编号为$1$的结点到2，也可以从编号为2的结点到$1$。

### 2 有向图

​		在有向图中，点与点之间是有一种顺序关系的(这种关系的具体讲解将在后面有向图的拓扑排序中讲解)。连接各个结点之间的之间的边具有方向性(带有箭头的)，下图是它的一个例子:

==示例:==

![Graph2](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pbdoj01yj208004c747.jpg)

​																											图 1

​		从上图中，我们可以看出有向图这个边是单向通行的，我们能从编号为$1$的结点到编号为$2$的结点，即存在边$(1,2)$。但反之不行，因为不存在边$(2,1)$。无向图中的一条边等价于有向图中两个结点互相连接，如下图所示:

==示例:==

​                                                                             	![Graph5](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pdknu6idj2051053mx0.jpg)



​		

​		我们将有向图中的一个结点$u$的==出度==表述为$\exist v\in V$使得$(u,v)\in E$的$v$的数量。结点$u$的==入度==的定义和出度相反。入度的表述为$\exist v\in V$使得$(v,u)\in E$的$v$的数量。我们拿前面的图1举例，编号为2的结点的出度为0，入度为2。再比如编号为3的结点出度为2，入度为1。

### 3 加权图

​		实际应用中我们的无向图和有向图一般都是加权的，我们赋予每一条边一个权值(就像我们日常生活的交通路网中每条路都有一个长度一样)。假设$\exist u,v\in G.V$，并且$\exist(u,v)$，那么我们将这条边的权值即为$w(u,v)$，我们将其值的大小写在边上，如下图所示:

==示例:==

​                                                            		![Graph3](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pbpkitacj208k04k3yg.jpg)

​		

​		上图是加权有向图，相对的，也有加权无向图。在加权图中，最基本的应用就是我们可以计算图中点到点的最短路近，这将在图算法中专门讲出，数据结构专栏不涉及此内容。

### 4 图的一些性质

​		图具有很多性质，这里只涉及了一部分，大多数是为后面要提到的算法服务的。

#### 4.1 图的连通性

​		在无向图中，如果对于图中的两个点$u,v\in V$，存在一条从$u$到$v$的路径，或者说$u$经过有限条边可以到达$v$，那么我们说$u$和$v$是==连通==，否则，它们两个就是==不连通==的。而如果$u$仅用一条边就能到$v$，那么我们说$u$和$v$是==相邻==的。

​		如果一个无向图中$\forall u,v\in V(u\neq v)$ ，都是连通的两点，那么我们说这个图是连通的，称为==连通无向图==。否则就是不连通的。对于如下示例中，第一张图是连通的，第二张图由于结点4和结点5不连通，所以整个图不连通。

==示例:==

![Graph9](https://tva1.sinaimg.cn/large/e6c9d24egy1h0rnpyd58sj20j7062t8v.jpg)



​		对于有向图，连通性将会稍微复杂点，如果我们把有向图中的所有有向边换成无向边后变成的无向图是连通的，我们称其具有==弱连通性==，但我们很少会研究图的弱连通性。

​		如果在有向图中$\forall u,v\in V，(u\neq v)$都有，$u$经过有限条边能达到$v$，并且$v$能通过有限条边能到达$u$(也就是说这个条件对图中所有的结点对都成立)，我们就说这个有向图具有==强连通性==。

​		例如，上面中的图1是弱连通性的，我们知道，如果把无向图中的边替换成两个互相指向的有向边，这个图必然是强连通的，但不一定所有强连通图都长这样，像下面这样的就是一个具有强连通性的图:

==示例:==

![Graph10](https://tva1.sinaimg.cn/large/e6c9d24egy1h0rodilwnzj207f04c0sm.jpg)

​																													图2



​			读者可以自行验证以下，其中任意一点都可以到达图中的其他所有点。

#### 4.2 图中的环

​		如果图中一点$u$，经过有限条边形成的==简单路径==(其中每条边都不一样)达到图中的一些结点，如果存在一条终点为自身的简单路径，那么我们说这个图是存在==环==的，注意到虽然我们说无向图中的便是双向的，但我们不能说经过这条边两次回到自身的路径为环，因为这不符合简单路径的定义。上面的图2就含有一个$1\rightarrow2\rightarrow3$的环。

#### 4.3 图和树

​		之前讲过树是图的一种特殊情况，那图在什么情况下会变成树呢。我们首先观察到，树中的每个结点都是有明确的关系的，也就是说如果一个结点$v$有一个祖先结点$u$(这里祖先结点是值可以通过指向孩子结点指针连续下降最终能访问到结点$v$的结点)。那么这个祖先结点$u$绝对不可能再是结点$v$的子结点或通过结点$v$连续下降能访问到的结点了。也就是说树里面是不可能出现下图所示的情况。

==示例:==

![Graph11](https://tva1.sinaimg.cn/large/e6c9d24egy1h0rpcydvhsj204h063mx1.jpg)

​		

​		这里出现了环，所以我们知道树肯定是一个无环的图。其次树的根结点可以访问到其他所有结点，所以树是一个有向无环图，其中$\exist u\in V$,使得$u$能通过有限条边到达其余所有结点，且这个$u$是唯一的。注意到这样的图具有弱连通性。

### 5 图的表示

​		这里我们将介绍两种使用较多的图的表示法，邻接链表和邻接矩阵。两种方法都可以表示有向图和无向图。

#### 5.1 邻接链表表示法(**Adjacency list**)

​		在图$G=(V,E)$中，邻接链表表示由一个包含$|V|$条链表的数组$array$所构成，数组中的每个索引，代表叫一个结点的编号，为了和数组对应，我们结点的编号从$0$开始，最后一个结点的编号为$|V|-1$。然后在数组该索引处对应的链表所存储的结点是与其相连的结点的编号，这里需要注意的是，在有向图中，假设索引处对应的结点为$u$，那么其对应链表存储的结点是其指向的结点，也就是说，假设存在另一个和其相连的结点$v$，且它们在有向图中存在$(u,v)$，那么$v$就在$u$所对应的链表中，这种表也叫==出度表==，每个结点链表的长度就是其出度，相对的，还有==入度表==，之后的示例都为==出度表==。而在无向图中，只要$v$与其相邻，那么起就在对应的链表中。我们对上面提到的无向图和有向图重新编号，然后用邻接链表法表示，如下图所示:

==示例:==

![Graph4](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pda8ce2fj20kp0d8aaq.jpg)

​		

​		我们看到对于有向图的邻接表来说，其含有所有链表的总结点数为$|E|$。而对于无向图中，所有链表的总结点数位$2|E|$。(因为无向图中的一条边是双向的)。所以对于不管是无向图和有向图，其邻接链表表示法所需的存储空间需求位$\Theta(V+E)$ 。

​		对于加权的有向图或者无向图，我们可以直接将$w(u,v)$权值存放在对应的链表结点中，例如$w(u,v)$应该存放在$array[u]$对应链表中$v$所在的那个结点(有向图)。对于无向图，$array[v]$对应链表中$u$所在的结点也要存放$w(u,v)$。

​		下面我们给出加权邻接链表的有向图的ADT描述。

==实现代码:==

```c++
#ifndef __ADJACENCYLIST_HPP__
#define __ADJACENCYLIST_HPP__
#include <vector>
struct Node
{
    Node(int a, int b, int c):vertex1(a),vertex1(b),weight(c),next(nullptr){}
    Node(int a, int b, int c, Node* node):vertex1(a),weight(b),weight(c),next(node){}
    int vertex1;//结点编号
    int vertex2;//结点编号
    int weight;//权值
    Node* next;//下一个结点
};
class adjacencyList//有向加权图的邻接链表表示
{
public:
    adjacencyList();//构造函数
    ~adjacencyList();//析构函数
public:
    int getVertexNum();//获取图中结点数
    int getEdgeNum();//获取图中的边数
    int getWeight(int a, int b);//获得该边的权值
    void insertEdge(int a, int b, int value);//插入一个条边。
    int insertVertex();//在图中增加新的点并返回该点点编号。
    void eraseEdge(int a, int b);//删除对应的边
    void eraseVertex();//删除该结点，并将和该结点相连的边删除
private:
    std::vector<Node* > _array;//存储邻接链表的数组
    std::vector<int> _freeSerialNum;//记录未使用的编号。
    int _numOfVertex;//记录结点数
    int _numOfEdge;//记录边的数目。
};
#endif
```

​		以上是其ADT描述，为了方便起见，其中我们使用了标准库的$vector$来充当数组，用来存储链表的头结点，其他函数我们将在图的基本操作中介绍。这里讲一下结构体$Node$的两个成员$vertex1$和$vertex2$，他们分别代表边$(u,v)$的$u$和$v$的编号。

​		我们发现邻接链表表示法要判断$(u,v)$是否为图$G$中的一条边时，需要扫描链表，效率可能没那么高。因此要想解决这个开销，我们还有另外一种表示法，邻接矩阵表示法。

#### 5.2 邻接矩阵表示法(**Adjacency matrix**)

​		邻接矩阵表示法本质上就是一个二维数组，我们用$matrix_{ij}$表示，其中$i,j\in[0,|V-1|]$ ，同样每个索引代表一个结点的编号。因此邻接矩阵法的空间开销有点大，为$\Theta(|V|^2)$，由于一般来讲$|E|$会比$|V|$小很多，因此邻接矩阵更像是一个==稀疏矩阵==。矩阵中每个结点的值，在加权的条件下满足下面的条件:
$$
matrix_{ij}=\begin{cases}
\begin{aligned}
&w(i,j)&(i,j)\in E\\
&0&(i,j)\notin E 
\end{aligned}
\end{cases}
$$
​		上面$i$表示行索引，而$j$表示列索引。下面我们给出无向加权图和有向加权图的矩阵表示法的示例:

==示例:==

​                             		![Graph6](https://tva1.sinaimg.cn/large/e6c9d24egy1h0pf05vmkfj20i70dadgp.jpg)

​		

​		我们看到矩阵中很多值为0，这些空间在链表中都被节约掉了，但是其判断一条边是否在$E$中非常快，我们只需要判断$matrix[i][j]$是否不为0即可，时间复杂度为$O(1)$。但是无向图的缺点是空间开销可能较大，特别是在==稀疏图==的情况下，会形成一个稀疏矩阵。因此它适用于比较稠密的图。而应对于==稀疏图==，我们更倾向于使用邻接链表。

​		除此之外，我们看下无向图的邻接矩阵，我们可以发现它是斜对称的，这是因为我们有$\_matrix[a][b]=\_matrix[b][a]$(双向连接)。

​		下面给出加权无向图的邻接表示法的ADT描述。

==实现代码:==

```c++
#ifndef __ADJACENCYMATRIX_HPP__
#define __ADJACENCYMATRIX_HPP__
#include <vector>
class ADjacencyMatrix
{
public:
    adjacencyMatrix();//构造函数
    ~adjacencyMatrix();//析构函数
public:
    int getVertexNum();//获取图中的结点数
    int getEdgeNum();//获取图中的边数
    int getWeight(int a, int b);//获得改边的权值
    void insertEdge(int a, int b, int value);//插入一个条边。
    int insertVertex();//在图中增加新的点并返回该点点编号。
    void eraseEdge(int a, int b);//删除对应的边
    void eraseVertex();//删除该结点，并将和该结点相连的边删除
private:
    std::vector< vector<int> > _matrix;//邻接矩阵
    std::vector<int> _freeSerialNum;//记录未使用的编号。
    int _numOfVertex;//记录结点数
    int _numOfEdge;//记录边的数目。
};
#endif
```

​		和邻接链表相似，我们使用标准库的$vector$来建立二维数组。

## 三、图的基本操作

​		这一小节我们介绍一些图的基本操作，我们主要以加权图为例(无权图更加简单)，然后我们会分别给出邻接链表形式和邻接矩阵形式，其中邻接链表形式的为有向图，邻接矩阵为无向图。

### 1 获取边的权值

​		这个操作需要我们根据给定两个结点的编号$u,v$，来获取$w(u,v)$ 。

#### 1.1 邻接链表

​		对于加权有向图邻接链表，我们首先根据编号$u$访问对应数组索引，然后扫描链表找到其$vertex2=v$的结点，然后就能获取其权值了。我们也可以通过这个函数判断这条边是否在图中，如果不存在这条边，那么这个函数将返回0，代码实现如下:

==实现代码:==

```c++
int adjacencyList::getWeight(int vertex1, int vertex2)
{
    if (vertex1 < 0 || vertex1 >= _array.size() || vertex2 < 0 || vertex2 >= _array.size())
    {
        throw std::invalid_argument("the serial number of vertex should be > 0 and < the max serial Of vertices!,");
    }
    Node* targetNode = _array[vertex1]->next;
    while (targetNode != nullptr && targetNode->vertex2 != vertex2)  
    {
        targetNode = targetNode->next;
    }
    if (targetNode == nullptr)
    {
        return 0;
    }
    return targetNode->weight;
}
```

​		需要注意的是我们的链表是有头结点，所以有`Node* targetNode = _array[vertex1]->next;`我们跳过了头结点

==时间复杂度:==取决链表中结点的个数，我们知道在有向图中，所有链表的所有结点总数为$|E|$，所以在最糟糕的情况下，所有边都在同一个链表中，且代查找的边不存在，时间复杂度为$O(E)$。

#### 1.2 邻接矩阵

​		对于加权无向图的邻接矩阵，访问操作非常简单，我们只要像访问数组一样访问二维数组就行了(如$\_matrix[u][v]$)。

==实现代码:==

```c++
int adjacencyMatrix::getWeight(int vertex1,int vertex2)
{
    if (vertex1 < 0 || vertex1 >= _matrix.size() || vertex2 < 0 || vertex2 >= _matrix.size())
    {
        throw std::invalid_argument("the serial number of vertex should be > 0 and < the total num Of vertices!,you can call getVertexNum to get it!");
    }
    return _matrix[vertex1][vertex2];
}
```

==时间复杂度:==$O(1)$。

### 2 插入边

​		这个操作需要对图中已经含有的结点$u,v$，生成一条边$(u,v)$，如果已经含有边了，那么这个操作无影响。

#### 2.1 邻接链表

​		首先检查这个边是否存在了，如果不存在，我们在链表的头结点插入新的$Node$。

==实现代码:==

```c++
void adjacencyList::insertEdge(int a, int b, int value)
{
    //w我们可以直接在链表的头结点插入边，但是我如果过考虑插入重复边的情况下
    //我们应该先检测这条边是否存在了
    if (getWeight(a, b) != 0)
    {
        std::cout << "insert failed, the edge already existed. you can use modifyWeight() to modify weight." << std::endl;
        return;
    }
    _array[a]->next = new Node(a, b, value);
    _numOfEdge++;
}
```

==时间复杂度:==插入到链表表头只需要$O(1)$，但我们之前检查边是否存在需要$O(E)$，所以总时间为$O(E)$。当然了，如果考虑上帝视角，使用者应该自己知道是否插入了一个重复的边的。那么这种情况下就不需要检查，时间复杂度为$O(1)$

#### 2.2 邻接矩阵

​		对于无向图的邻接矩阵，我们和邻接链表一样先检查边是否存在，插入时我们应该同时对$\_matrix[u][v]$和$\_matrix[v][u]$都更新其$weight$值。

==实现代码:==

```c++
void adjacencyMatrix::insertEdge(int a, int b, int value)
{
    //有向图的边是双向的，因此我们得同时修改matrix[a][b]和matrix[b][a]
    if (getWeight(a, b) != 0)
    {
        std::cout << "insert failed, the edge already existed. you can use modifyWeight() to modify  weight." << std::endl;
        return;
    }
    _matrix[a][b] = value;
    _matrix[b][a] = value;
    _numOfEdge++;
}
```

==时间复杂度:==检查边是否存在需要$O(1)$，插入边需要$O(1)$，总体上需要$O(1)$。

### 3 插入结点

​		插入结点是我们应该先考虑我们存储空闲编号的队列是否为空，这个队列出现是为了解决这样的情况，但我们删除一个结点时，不管是邻接矩阵函数邻接链表，如果删除的结点在中间的话，那么我们后面的结点的编号要填补空位，像下面的图那样:

==示例:==

![Graph7](https://tva1.sinaimg.cn/large/e6c9d24egy1h0qinihttsj20ig0dkmxt.jpg)



​		可以看到的是删除编号为3的结点造成了空缺。如果我们用后面的编号的结点去填补，那么后面所有结点的编号都会减少一，这将会会给用户之前插入结点并获得该结点编号产生不一致。因此为了保证一致性，我们不将后面的结点填补上去，而是额外用一个队列存储空闲编号(一个结点被删除后，其所用的编号变为空闲编号)，这样在下次插如结点时，我们先查看队列中是否有空闲的编号，如果有，我们直接用这个编号即可。

#### 3.1 邻接链表

​		邻接链表创建新结点时为该结点所对应的链表建立了一个头结点，体现在下面代码中的$emplace\_back$中，创建头结点我们使用了$Node$的构造函数。

==实现代码:==

```c++
int adjacencyList::insertVertex()
{
    if (_freeSerialNum.size() != 0 )
    {   //如果有空闲的编号，直接回传空闲编号即可。
        int serialNum =  _freeSerialNum.front();
        _freeSerialNum.pop();//弹出这个空闲编号
        return serialNum;
    }
    _array.emplace_back(new Node());//创建新结点
    _numOfVertex++;
    return _numOfVertex - 1;//返回其编号
}
```

==时间复杂度:==$O(1)$。

#### 3.2 邻接矩阵

==实现代码:==

```c++
int adjacencyMatrix::insertVertex()
{
    if (_freeSerialNum.size() != 0 )
    {   //如果有空闲的编号，直接回传空闲编号即可。
        int serialNum =  _freeSerialNum.front();
        _freeSerialNum.pop_front();
        return serialNum;
    }
    _matrix.emplace_back(vector(_numOfVertex + 1, 0));//添加新的一行
    for(int i = 0; i < _matrix.size() - 1; i++)//对原来的矩阵增加一个列
    {
        _matrix[i].emplace_back(0);
    }
    _numOfVertex++;
    return _numOfVertex - 1;
}
```

==时间复杂度:==在有空闲编号的情况下为$O(1)$，除此之外时间复杂度为$O(1+V+V)=O(V)$ ，分别为增加一列和增加一行的开销。

### 4 删除边

#### 4.1 邻接链表

​		对于加权有向图删除边是较为简单的，对于边$(u,v)$，首先找到结点$u$所在的链表，然后再链表中搜索`Node->vertex2=v`的结点删除这个结点就好了。

==实现代码:==

```c++
void adjacencyList::eraseEdge(int a, int b)
{
    if (a < 0 || a >= _array.size() || b < 0 || b >= _array.size())
    {
        throw std::invalid_argument("the serial number of vertex should be > 0 and < the total num Of vertices!,you can call getVertexNum to get it!");
    }
    Node* preNode = _array[a];//指向该量表的头结点
    Node* targetNode = preNode->next;
    while(targetNode != nullptr || targetNode->vertex2 != b )
    {
        preNode = targetNode;
        targetNode = targetNode->next;
    }
    if(targetNode != nullptr)
    {
        preNode->next = targetNode->next;
        delete targetNode;//释放空间
        _numOfEdge--;
    }
}
```

==时间复杂度:== 为搜索链表的时间，最糟糕情况下为$O(E)$，和获取边的权值是一样的。

#### 4.2 邻接矩阵

​		这个较为简单，我们只需要把矩阵对应的位置置为0即可。

==实现代码:==

```c++
void adjacencyMatrix::eraseEdge(int a, int b)
{
    if (a < 0 || a >= _matrix.size() || b < 0 || b >= _matrix.size())
    {
        throw std::invalid_argument("the serial number of vertex should be > 0 and < the total num Of vertices!,you can call getVertexNum to get it!");
    }
    if (_matrix[a][b] != 0)
    {
        _matrix[a][b] = 0;//置为0即可
        _matrix[b][a] = 0;//无向图要有这部。
        _numOfEdge--;
    }
}
```

==时间复杂度:==$O(1)$。

### 5 删除结点

​		删除结点我们得把删除后的结点加入空闲编号的队列。但是在删除之前，我们得先考虑待删除结点的编号是否在空闲编号中，如果是，我们应当退出这个算法。这是因为空闲编号对应的结点本身就不在图中。

#### 5.1 邻接链表

​		对于邻接链表来说，在判断完待删除的结点编号不在空闲编号中之后，我们访问该结点所在的链表，然后把该链表表出了头结点以外全部清空。除此之外，由于别的结点也可能有指向待删除结点的边，因此我们还需要扫描别的结点，找到这样的边并删除。

==实现代码:==

```c++
void adjacencyList::eraseVertex(int a)
{
    if (a < 0 || a >= _array.size())
    {
        throw std::invalid_argument("he serial number of vertex should be > 0 and < the max serial Of vertices!");       
    }
    //首先要确保这个结点编号不在空闲编号中
    if (std::find(_freeSerialNum.begin(), _freeSerialNum.end(),a) != _freeSerialNum.end())
    {
        return;//直接返回，因为空闲编号代表的结点世纪不存在于图中
    }
    //我们需要扫描整个图中去寻找a的入边并删除，同时还要删除a本身的出边
    //先删除a本身的出边
    Node* preNode = _array[a];
    Node* targetNode = preNode->next;
    while (targetNode != nullptr)
    {
        preNode = targetNode;
        targetNode = targetNode->next;
        delete preNode;
        _numOfEdge--;
    }
    for (size_t i = 0; i < _array.size(); i++)
    {
        preNode = _array[i];
        targetNode = _array[i]->next;
        while(targetNode != nullptr && targetNode->vertex2 != a)
        {
            targetNode = targetNode->next;
        }
        if (targetNode != nullptr)
        {
            preNode->next = targetNode->next;
            delete targetNode;//删除这个结点
            _numOfEdge--;
        }
    }
    _numOfVertex--;
    //将该结点加入空闲编号
    _freeSerialNum.push_back(a);
}
```

==时间复杂度:==最坏情况下我们需要遍历所有链表的所有结点，时间复杂度为$O(E)$。

#### 5.2 邻接矩阵

​		假设待删除结点为$a$,那么我们只需要将$\_matrix[a][i]$和$\_matrix[i][a]$置为0即可。其中$i$的范围为为矩阵的大小。

==实现代码:==

```c++
void adjacencyMatrix::eraseVertex(int a)
{
    if (a < 0 || a >= _matrix.size())
    {
        throw std::invalid_argument("he serial number of vertex should be > 0 and < the max serial Of vertices!");       
    }
    //现在空闲链表表中寻找是否有该编号
    if (std::find(_freeSerialNum.begin(), _freeSerialNum.end(),a) != _freeSerialNum.end())
    {
        return;
    }
    //先将行a处的所有位置置为0.
    for (auto i = _matrix.begin(); i != _matrix.end(); i++)
    {
        if (*i != 0)
        {
            *i = 0;
            _numOfEdge--;
        }
    }
    for (size_t i = 0; i < _matrix.size(); i++)
    {
        //在每一行中找到这个点的编号对应的位置，即列a，并将其置为0
        _matrix[i][a] = 0;
    }
    _freeSerialNum.push_back(a);//将删除后的结点编号加入空闲链表。
    _numOfVertex--;
}
```

==时间复杂度:==我们总共最多只需要将$2V-1$个位置置为0，因此时间复杂度为$O(V)$。

### 6 修改边权值

​		修改边权值很简单，我们只需要先判断这条边是否在图中，如果在图中，然后找到这个边修改即可。下面直接给出代码。

#### 6.1 邻接链表

==实现代码:==

```c++
void adjacencyList::modifyWeight(int a, int b, int value)
{
    if (getWeight(a,b) == 0)
    {
        std::cout << "you can't use this function when the Edge you want to modify is not exist,maybe you should call insertEdge() " << std::endl;
    }
    Node* targetNode = _array[a]->next;
    //找到这个结点
    while(targetNode != nullptr && targetNode->vertex2 != b)
    {
        targetNode = targetNode->next;
    }
    if (targetNode == nullptr)
    {
        return ;
    }
    targetNode->weight = value;//修改权值。
}
```

==时间复杂度:==$O(E)$。

#### 6.2 邻接矩阵

==实现代码:==

```c++
void adjacencyMatrix::modifyWeight(int a, int b, int value)
{
    if (getWeight(a,b) == 0)
    {
        std::cout << "you can't use this function when the Edge you want to modify is not exist,maybe you should call insertEdge() " << std::endl;
    }
    //和插入的时候几乎一样，但其只是在已有边的基础上修改。
    _matrix[a][b] = value;
    _matrix[b][a] = value;
}
```

==时间复杂度:==$O(1)$。

## 四、图搜索算法

​		图的搜索算法非常重要，因此我们单独拿出来讲。搜索图就是通过边访问图中的结点。本质上和树的遍历很相似，常用的图的遍历算法有==广度优先搜索==（Breadth-Frist-Search，BFS)和==深度优先搜索==(Deepth-First-Search，DFS)。

### 1 广度优先搜索

​		广度优先搜索算法较为简单，它可以简单的描述为如下的过程:开始的时候，我们选定一个搜索的起始结点将其加入一个用于存储的数据结构。然后我们反复从这个数据结构中选取一个结点访问该结点，然后将其相邻的结点加入该数据结构中，并将这个结点(访问过的)从该数据结构中移除，并标记为已经访问过的。需要注意我们不能把已经访问过的数据加入数据结构中，我们重复上述过程，知道该数据结构中不存在结点。

​		我们根据图1(重新编号后的，编号从0开始)来完成以下对上述过程的步骤，(需要要注意的是后面的算法都将有向图的邻接链表法完成)。

==示例:==

​		我们选定编号为0的结点作为起始访问结点。

![Graph8](https://tva1.sinaimg.cn/large/e6c9d24egy1h0rmurn780j20kg0wr404.jpg)

​		

​		在上面的示例中，2有个相邻结点1，但是其前一次访问中访问过了，所以我们不将其加入队列。除此之外我们可以看到官渡优先搜索生成的访问序列是一棵树，我们将其称为==广度优先树==，其根结点为起始访问结点。同时我们注意到我们的广度优先搜索并没有访问到图中的所有结点，比如上图中5号结点就没被访问到，这是因为图本身不是==连通==的，**广度优先搜索的生成序列代表了起始结点可以通过有限条边访问到的所有结点**。广度优先搜索是一个从起始结点不停向外扩散的算法，后面我们会看到，广度优先搜索可以用来寻找初始结点到其可访问结点最短路径(最少边路径)。

​		至于如何存储被加入的结点，我们一般采用队列来存储，因为其含有先进先出的性质，先加入队列的结点应该最先被访问，这符合常识。以下给出有向图的邻接表示法的BFS的实现。

==实现代码:==

​		对于如获取一个结点是否已经访问过，我们可以用一个数组记录，数组初始化为$0$，如果编号为$i$的结点已经被访问过了，我们将数组索引为$i$的位置的值置为1，表示该结点已经访问过了。

```c++
void adjacencyList::BFS(int a)
{
    if (a < 0 || a >= _array.size())
    {
        std::cout << "you can't call this function on vertex which doesn't exist" << std::endl;
    }
    std::vector<int> temp(_array.size(),0);
    std::list<int> queue1;
    queue1.push_back(a);
    while (!queue1.empty()) 
    {
        int vertex = queue1.front();//取出对首元素
        std::cout << vertex << " ";//打印编号
        queue1.pop_front();//弹出这个结点
        temp[a] = 1;//标记为已经访问过了。
        Node* targetNode = _array[a]->next;//访问其相邻结点
        while(targetNode != nullptr)
        {
            if (!temp[targetNode->vertex2])//如果未访问过这个结点
            {
                queue1.push_back(targetNode->vertex2);//相邻结点加入队列
            }
        }
    }
}
```

==时间复杂度:==初始化用于记录是否重复的数组需要$O(V)$，然后通过边从初始结点访问其他结点需要$O(E)$,总时间为$O(V+E)$。

​		上面的算法中用到了队列，不知道读者有没有想到在讲树时，我们曾经遇到过一种层序遍历的遍历算法，里面也用到了队列，读者可以比较一下这两种算法，其实不难发现，层序遍历一定程度上就是一种广度优先搜索。除此之外，我们上面的代码为了简便，采用了较为简单的打印形式作为对该结点的访问。

#### 1.1 最短路径

​		下面证明一些广度优先搜索的一些性质，首先定义一个概念。我们定义从初始结点$s$到结点$v$的==最短路径距离==为$\delta(s,v)$为从结点$s$到结点$v$的所有路径里面的**最少边数**，(这里的定义是建立在无权图上的)，这一小节中我们将证明广度优先搜索可以正确计算出最短路径。

==引理1:==给定$G=(V,E)$，$G$为一个有向图或无向图，设$s\in V$为任意结点，则对于任意边$(u,v)\in E$，$\delta(s,v)\le\delta(s,u)+1$。

==证明:==如果结点$u$能从$s$到达，那么对于从$s$到达$v$的最短路径，它要么先从$s$到$u$的路径中，然后再经过$(u,v)$到达$s$。要么不走这条路，痛殴其他路径达到$v$，当走上述第一条路径是干好满足不等式因为路径边数位$\delta(s,u)+1$，当走别的路径时，其必然会比$\delta(s,u)+1$小，因为如果比这个大，那根据定义$\delta(s,v)=\delta(s,u)+1$ ，仍然满足条件。现在再看下不能到达的情况，这种情况下$\delta(u,s)=\infty$，不等式自然成立。

​		在继续下面的内容之前，我们给广度优先遍历中的每个结点赋予一个额外的属性，假设我们广度优先搜索算法的初始结点选为$s$，我们对从$s$执行广度优先算法执行时所能搜索到的所有的点$v$，定义$v.d$为初始结点$s$到$v$的边数(我们之后将要证明这是==最短路径距离==)。我们要在算法中统计这个距离很简单，我们设初始结点的距离$s.d=0$，其余所有结点为$\infty$。那么其相邻结点的距离就为$s.d+1$。我们根据这个性质，在上面代码的第20行后，我们可以添加类似 `vertex.d = temp.d + 1`的代码(其中vertex为代插入队列的结点，也是temp的相邻结点)，然后将这个结点编号和距离组成的$pair$加入队列。

==引理2:==给定$G=(V,E)$，$G$为一个有向图或者无向图 ，假定BFS一给定点$s\in V$作为源结点在图$G$上运行。那么在BFS运行结束时，对于每个结点$v\in V$，BFS计算出的$v.d$满足$v.d\ge\delta(s,v)$。

==证明:==我们采用数学归纳法去证明，首先，在初始时刻，这个是必然成立的，因为初始时刻$s.d=0$，而其余任意结点的距离都为$\infty$ .所以初始时刻是必然成立。

​		其次我们假设当我们运行到结点$u$时有$u.d\ge\delta(s,u)$。然后扫描$u$所对应的链表是发现结点$v$，也就是说存在边$(u,v)$，由引理1，我们知道有:
$$
\begin{equation}
\delta(s,v)\le\delta(s,u)+1\tag{1}
\end{equation}
$$
​		而我们知道$v.d=u.d+1$，所以我们有:
$$
\begin{split}
\qquad\qquad \qquad \qquad v.d=&\space u.d+1\\
\ge&\space\delta(s,u)+1\qquad\qquad&(由归纳假设)\\
\ge&\space\delta(s,v)\qquad\qquad&(由式(1))
\end{split}
$$
​		因此得证。

​		下面我们要进一步证明$v.d=\delta(s,v)$，因此我们需要进一步研究队列在这之中的运行过程。

==引理3:== 假定BFS在等图$G=(V,E)$的过程中，队列$Q$包含结点为$<v_1,v_2,\dots,v_r>$ 。这里$v_1$是队列$Q$的头，$v_r$是队列$Q$的尾。那么$v_r.d\le v_1.d+1$,并且对于$i=1,2\dots,r-1$，$v_i.d\le v_{i+1}.d$。

==证明:==初始情况下队列中只有一个初始结点$s$，所以结论成立。

​		其对于归纳假设部分，我们必须证明在入队和出队操作时引理都成立，首先证明出队操作，如果头结点$v_1$被删除，那么紧随其后的$v_2$就会成为新的头结点。根据归纳假设，我们有$v_1.d\le v_2.d$，但是我们有$v_r.d\le v_1.d+1\le v_2.d+1$，且余下的不等式不受影响，因此$v_2$为有结点是引理成立。

​		现在观察入队，设新加入的结点$v$为$v_{r+1}$。考察我们的算法，这个结点入队就意味着预期相邻的结点$u$已经出队了，根据归纳假设，我们有新的头结点$v_1$满足 $v_1\ge u.d$。因此，$v_{r+1}.d=v.d=u.d+1\le v.d+1$,根据归纳假设，我们还有$v_r.d\le u.d+1$，因此$v_r.d\le u.d+1=v.d=v_{r+1}.d$。所以加入队列时引理也成立。

==推论1:==假定在执行BFS时，结点$v_i$和结点$v_j$都加入到队列$Q$中，并且$v_i$在$v_j$前面入队，则在$v_j$入队时，我们有$v_i.d\le v_j.d$。

==证明:==由引理3，我们可以轻松推出。

==定理1:==设$G=(V,E)$为一个有向图或者无向图，又假设BFS以$s$为源结点在图G上运行，那么在算法执行的过程中，$BFS$将发现源结点$s$可以到达的的所有结点$v\in V$，并在算法中止时，低于所有的$v\in V$，$v.d=\delta(s,v)$。而且对于任意可从$s$到达的结点$v\neq s$，从源结点到结点$v$的其中一条最短路径为从结点$s$到$v$的前驱结点$u$(也就是和$v$相邻，但是其弹出时$v$入队的结点)的最短路径再加上边$(u,v)$.

==证明:==我们使用反证法证明。首先假设存在一条路径使得$v.d\neq \delta(s,v)$，由引理2我们知道$v.d\ge\delta(s,v)$，既然不想等，那就说明$v.d\ge\delta(s,v)$，其次，结点$v$是可到达的，不然的话我们有$\delta(s,v)=\infty>v.d$，假设$v$的前驱结点为$u$并且其在$s$到$v$的最短路径上，我们有$\delta(s,v)=\delta(s,u)+1$，因为$\delta(s,u)<\delta(s,v)$并且因为我们对结点$v$的选择，所以有$u.d=\delta(s.u)$，我们合并起来分析有:
$$
\begin{equation}v.d>\delta(s,v)=\delta(s,u)+1=u.d+1\tag{2}\end{equation}
$$
​		我们分情况讨论，当我们的结点$v$还未加入过队列时，我们有$v.d=u.d+1$(因为$u$是$v$的前驱)。矛盾。另外，如果$v$已被访问过，那么该结点已经在队列中被删除了，根据推论1，那么我们有$v.d\le u.d$(因为$u$是$v$的前驱，$u$在队列中一定排在其前面，其先入对)，仍然与$(2)$矛盾。因此到最后得证。

### 2 深度优先搜索

​		深度优先搜索是相对于广度优先搜索而言，它不是像广度优先搜索那样发散式的搜索。它每次都往更"深"的结点搜索，它可以简单的描述为下面的过程:从一个初始结点开始，我们搜索其第一个**未被搜索过的**相邻结点，不访问，也不继续搜索其第二个相邻结点而是递归地搜索第一个未被搜索过相邻结点的第一个未被搜索过的相邻结点(有点绕)，这样的过程直到遇到空结点后返回，这时候我们就进入了递归回溯的状态(我们会不断走原来走过的搜索路径回到之前搜索过的结点)，递归回溯的过程中我们再访问结点，然后继续搜索其第二个相邻结点，一直持续在上面的过程，知道所有结点都被访问了。

​		为了更方便对深度优先搜索进行描述，这里给出一些方便与后面描述的说明。我们通过对结点涂色表明一个结点的状态。从上面的简单描述中可以看出，我们的深度优先搜索中结点可以被分为三种状态:(1)既没被搜索过也没被访问过，我们用**白色**代表其状态。(2)被搜索过但还没被访问过。我们用**灰色**代表其状态。(3)被搜索过也被访问过了，我们**黑色**代表其状态。其次假设结点为$v$，我们发现深度优先搜索也针对每个结点$v$记录下两个==时间戳==(可以理解为时间节点)。第一个就是其第一次被搜索到的时间戳。我们记为$v.f$，第二次就是其被访问时的时间戳我们记为$v.d$。

​		还有就是不同于广度优先搜索的是，出于其作用考虑，我们下面的深度优先搜索代码需要遍历到图中所有的结点，因此我们不会像广度优先搜索一样只针对一个起始结点做广度优先搜索，我们会针对特定的不同起始结点做深度优先搜索，然后和广度优先搜索一样，深度优先搜索会生成==深度优先搜索树==，不同起始结点将会生成不同深度优先搜索树的集合。我们称这个集合是一个==森林==，它包含了图中的所有结点，并且森林中的不同深度优先搜索树是不相交的，也就是说不同的树之间不含有相同的结点(这将会在后面证明)。这么做的原因是出于作用的考量，大多数运用深度优先搜索的算法都有类似的形式。

​		下面给出代码，我们仍然是以邻接链表法表示的有向图为例:

==实现代码:==

```c++
void adjacencyList::DFS()
{
    std::vector<int> stateList(_array.size(), 0);//状态为0表示为白色，1表示为灰色，2表示为黑色
    std::vector<std::pair<int,int>> timeList(_array.size(), {0,0});//记录每个结点的时间戳
    for (auto i = _freeSerialNum.begin(); i != _freeSerialNum.end(); i++)//刚开始我们扫描空闲编号的结点，并将其对应状态置为黑
    {
        stateList[*i] = 2;
    }
    int time = 0;
    //生成森林。
    for (size_t i = 0; i < _array.size(); i++)
    {
        if(stateList[i] == 0)
        {
            DFS(i, time, stateList, timeList);//调用重载函数开始生成不同的深度优先搜索树
        }   
    }
}
void adjacencyList::DFS(int a, int & time, std::vector<int> & stateList, std::vector<std::pair<int,int>> & timeList)
{
    time += 1;//时间加1，为搜索时间
    timeList[a].first = time;//记录v.d
    stateList[a] = 1;//变为灰色，说明被搜索到了(被发现了)
    Node* targetNode = _array[a]->next;
    while(targetNode != nullptr)
    {
        if (stateList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , stateList, timeList);//递归调用
        }
    }    
    //以下为回溯过程中的代码
    std::cout << a << " ";//打印该结点编号。
    stateList[a] = 2;//置为黑色
    time += 1;//时间戳加1
    timeList[a].second = time;//记录该时间戳为v.f
}
```

​		代码如上面所示，我们最后会生成一个森林，并且每个结点都有相应的时间戳，我们记录在`timeList`中，它记录了每个结点的时间对，包括其最开始被发现(被搜索到的时间)的时间和被访问到的时间。然后我们使用`stateList`记录其所处的状态，和$BFS$一样，我们用打印代表访问了这个结点。以上使用了递归版本的DFS，读者可以仿照二叉树后序遍历那样，使用栈的形式模拟递归的过程，自行完成使用栈完成DFS代码。

==时间复杂度:==如果我们排除递归调用函数的开销。我们初始化`timeList`和`stateList`需要$\Theta(V)$的时间，同样在过程中我们扫描了所有链表的所有结点，其为边的个数，所以需要时间$\Theta(E)$，总共的运行时间为$\Theta(V+E)$。

​		下面给出DFS运行的过程。如下图所展示的那样，我们仍然以重新编号后的图1为例(初始编号为0):

==示例:==

![Graph12](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wbg6vr1xj20fi17dq5v.jpg)

​                                             ![Graph13](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wbg1jhyrj20h71jx0wp.jpg)   

​                                              

​		

​		从上面的示例中，我们可以同时回顾一下树的后序遍历的过程，我们不难发现，其实树的后序遍历和图的单个深度优先树的生成非常相似。

#### 2.1 深度优先搜索的性质

​		这一小节我们将介绍一些深度优先搜索的一些性质。

##### 2.1.1 括号化定理

​		其中有一个重要的性质，就是深度优先搜索所生成的`timeList`有所谓的括号化结构，假设有结点$v$，我们可以用$(v$表示结点$v$的发现时间，用$v)$表示结点$v$完成访问的时间。然后我们将`timeList`展开，就可以生成嵌套的括号结构，例如上面所举的例子中，我们将`timeList`展开，为$(0(11)(2(3(44)3)2)0)(55)$，注意我们的栈开始沿着时间戳递增的顺序展开的，最早开始时间戳为1，展开时间戳为1的对应的结点，由于其在$v.f$那一行，就展开为$(0$，以此类推。我们也可以将时间戳标记在图中对应的结点上，这样更有利于我们展开，如下:

==示例:==

![Graph14](https://tva1.sinaimg.cn/large/e6c9d24egy1h0szlhhqdfj209p04c0sq.jpg)



​		上图中左侧的时间戳为$v.f$。

==定理2:==(括号化定理)对有向图或者无向图G进行的任意深度优先树中，对于任意两个结点$u,v$来说，下面三种情况只有一种成立:
$$
\begin{align}
& {(1)}\space区间[u.d,u.f]和区间[v.d,v.f]完全分离(也就是两个区间的交集为空集)，在深度优先森林中，结点u不是结点v的后代，结点v也不是\\&结点u的后代。\\
& (2)\space区间[u.d,u.f]将区间[v.d,v.f]包含在内，在深度优先树中，结点v是结点u的后代。\\
& (3)\space区间[v.d,v.f]将区间[u.d,u.f]包含在内，在深度优先树中，结点u是结点v的后代。
\end{align}
$$
==证明:==我们只需证明$u.d<v.d$的情况即可，因为另外一种情况可以对称的得证。这里我们需要再分两种子情况，当$v.d<u.f$时，根据算法我们肯定能得到$v$是结点$u$的后代，其次由于结点$v$在结点$u$后面被发现，所以根据算法，最后返回到结点$u$并访问时，结点$v$必然已经被访问过了。所以我们可以得到区间$[v.d,v.f]$在区间$[u.d,u.f]$内。另外一种子情况，当$u.f<v.d$时，我们知道对于一个结点$u.d<u.f$，$v.d<v.f$ ，于是我们有$u.d<u.f<v.d<v.f$，因此区间$[u.d,u.f]$和区间$[v.d,v.f]$是完全分离的，没有一个结点是在另一个结点为灰色的时候被发现。所以得证。

==推论2:==在有向挥着无向图$G$的深度优先森林中，结点$v$是结点$u$的真后代当且仅当$u.d<v.d<v.f<u.f$成立。

==证明:==可由定理2直接得出。

##### 2.1.2 白色路径定理

​		这个定理给出了在深度优先森林中，当一个结点是另一个结点的后代的另一个重要的特征。

==定理3:==(白色路径定理)在有向图或无向图中$G=(V,E)$的深度优先森林中，结点$v$是结点$u$的后代当且仅当在发现结点$u$的时间$u.d$，存在一条从结点$u$到结点$v$的全部白色结点所构成的路径。

==证明:==这是一个充分必要条件的证明题。先证明必要性，也就是我们已知结点$v$是结点$u$的后代，当$u=v$时，那么从结点$u$到结点$v$只包含结点$u$一个结点发现结点$u$时，结点$u$还处在白色状态(虽然马上就会被凃灰)。因此这种情况是成立的，另外考虑结点$v$不是结点$u$的情况，这时候我们根据推论2有$u.d<v.d$因此结点$v$在结点$u$被发现时仍然为白色，由于结点$v$可以为结点$u$的任意后代。所以我们可以得到结点$u$到结点$v$的简单路径全部由白色结点构成。得证。

​		接下来证明充分性。运用反证法，假定在时刻$u.d$时存在一条从结点$u$到结点$v$的全部白色结点组成的路径，但结点$v$的在深度优先树中不是结点$u$的后代。不失一般性，假定从结点$u$到结点$v$的全部结点除了结点$v$之外都是结点$u$的后代，我们取其中一个结点$w$，使得$w$为结点$v$的前驱，也为$u$的后代（$w$也可能就是$u$）。根据推论2，我们有$w.f<u.f$。因为结点$v$必须在结点$u$被发现之后但在结点$w$处理完之前被发现(注意到结点$v$处在一条白色的路径上，路径上的白色结点在$u$之后被发现，其次注意到$w$是其前驱，在其完成前$v$必须被发现，否则完成后就发现不了$v$了)，所以我们有$u.d<v.d<w.f\le u.f$。根据定理3，我们知道区间$[v,f,v,d]$只能包含在区间$[u.d,u.f]$内。然后根据推论，我们知道$v$必然为$u$的后代，矛盾，得证。

#### 2.2 边的分类

​		深度优先搜索还能将图$G=(V,E)$中的边进行分类。每条边的类型可以提供关于图的重要信息。例如之后我们介绍的后向边，我们之后将证明如果一个图是无环的，那么它将不产生后向边。首先我们介绍四种边的类型。

==树边:==为深度优先森林中的边，如果结点$v$是因为算法对边$(u,v)$的探索而首先被发现，则$(u,v)$为一条树边。

==后向边:==后向边$(u,v)$是将结点$u$连接到其在深度优先树中一个祖先结点的边。我们可以看到，这条边加入深度优先树中会导致深度优先树不再是树，因为出现了环。

==前向边:==是将结点$u$连接到其在深度优先树中的一个后代结点$v$的边。

==横向边:==这些边可以连接同一颗深度优先树中的结点，只要其中一个结点不是另外一个结点的祖先。也可以连接不同深度优先树的两个结点。

​		为了更好的进行举例说明，我们对下面的图从编号0开始进行深度优先搜索。

==示例:==

![Graph15](https://tva1.sinaimg.cn/large/e6c9d24egy1h0t3el8ialj20c604cjrf.jpg)



​		遍历后，我们会生成如下的经过时间戳标注的图(读者可自行验证验证)。

![Graph16](https://tva1.sinaimg.cn/large/e6c9d24egy1h0t3qfugzbj20dk04hjrj.jpg)





​		我们现在根据定义对其中的边进行标注。如下

![Graph17](https://tva1.sinaimg.cn/large/e6c9d24egy1h0t43l467sj20e304tjrl.jpg)



​																											图3



​		上面大些字母$T$代表树边，$B$代表后向边，$F$代表前向边，$C$代表横向边。如果只根据上面给出的定义，似乎还是有点难以理解，下面我们来通过DFS具体过程来探讨什么情况下是什么边，一般可以根据结点的颜色信息去获取这些边的信息。

​		当==第一次==探索边$(u,v)$时，根据结点$v$的颜色，我们可以对$(u,v)$进行分类:

​		(1) 当$v$为白色结点时，$(u,v)$必然是树边。

​		(2) 当$v$为灰色结点时，$(u,v)$必然是后向边。

​		(3) 当$v$为黑色结点时，$(u,v)$可能是前向边，可能是横向边。

​			a. $u.d<v.d$时为前向边。

​			b. $u.d>v.d$时为横向边。

​		首先来看(1)为什么成立，首先条件是第一次探索$(u,v)$，结点$v$为白色，说明其必然是第一次被发现，并且是通过边$(u,v)$而第一次发现，根据树边的定义:结点$v$是算法对$(u,v)$的首次探索而被发现。因此这是正确的。其次再看看(2)为什么成立，根据我们的算法，在第一次遇到结点时，会将白色结点涂成灰色，如果遇到灰色结点，说明之前已经发现过他了(上述代码的22～28行，我们跳过了黑色和灰色结点，只探索白色结点)。所以==当前==我们所处的结点(它的相邻结点有灰色结点，也就是代码22~28行中跳过的灰色结点)，必然在灰色结点为根的子树中(也可以说是子图，但深度优先搜索可以生成深度优先树，并且可以递归的定义，所以深度优先树中每个结点为根的子树其实也是深度优先树)，注意到这点你得知道这样一个事实:灰色结点还没有被访问(也就是代码第30行访问的代码)，也就是说其还在22 ~ 28行的循环中，而我们==当前==所处在的结点是在其之后遇到的。所以必然在其子树中。其实也可以类比后序遍历，我们知道深度优先搜索和后序遍历的过程非常相似，它们都是先访问其结点的子树最后再访问结点本身。下面就简单了，由于我们发现的结点$v$为灰色，说明当前结点$u$在$v$的子树中，所以$(u,v)$是$u$的一个连接到深度优先树中其祖先结点$v$的边，所以其为后向边。最后我们来分析第三种情况为什么成立，首先$v$为黑色结点，说明其已经被访问过了，那么结点$u$就不可能是结点$v$的后代(在其子树中)。所以其不可能是后向边，更不可能是树边。但是结点$v$就==有可能==是结点$u$的后代了，这是因为我们知道深度优先搜索会先遍历完子树在回过头来访问子树的子根结点。那么现在$v$为黑色，说明其已经访问完了，而==当前结点==$u$还未访问，所以==有可能==$(u,v)$是前向边，注意这里是有可能。因为结点$v$不一定就是结点$u$的后代，在这种情况下，那就是横向边。具体情况可以由$v.d$来区分，如果$u.d<v.d$ ，那说明了$u$先被发现，但最后出现了$v$比$u$先访问，那就说明了$v$是$u$的后代，因为比$u$晚发现的结点要么是其后代要么是其兄弟结点(在深度优先搜索树中)或者以兄弟结点为根的子树中的结点，但其兄弟结点或者以兄弟结点为根的子树中的结点必然在$u$之后被访问(这是因为$u$的父结点先发现$u$，因为我们这里说明的是$u.d<v.d$，如果兄弟结点是$v$的话，其必然要比$u$晚发现)，所以其只能是是其后代，所以为前向边当$v.d<u.d$时，说明$v$比$u$先发现，那么$v$只可能是其兄弟结点或者以兄弟结点为根的子树中的结点或者祖先结点。但是$v$比$u$先访问。所以其必然不可能是其祖先结点，因为其祖先结点必然比$u$晚访问(深度优先搜索，先访问子树吗最后访问结点本身)。所以其只能是兄弟结点或者以兄弟结点为根的子树中的结点。$u$的兄弟结点和$u$处在棵以它们两个各自为根的子树中，所以这条边是“横跨”两棵树的，所以我们叫它横向边。需要注意的是，上述讨论的是在一颗完整的深度优先搜索树的情况下，如果在森林中，那么不同树之间的连线必然是横向边，但我们需要把兄弟结点替换成别树或者别的树中的结点即可证明。

​		我们可以以图3为例子举例说明，树边不举例，较为简单。5号结点指向7号结点的边为后向边，这是因为我们先发现7号结点，7号涂灰，然后发现6号，再发现5号。之后又发现了7号为灰色，所以其为后向边(这其实形成了环)。再者我们看下0号结点指向4号的前向边，0号结点发现4号的时候其已经是黑色的了，这是因为4号同时还是7号的子结点，7号此时已经访问完了(为黑色)，所以其4号子结点必然为黑色。同时还因为0号结点比4号结点早访问，所以为前向边。

​		横向边为了更好的说明，我们将上面的图少做转换，转换为类似于树的形式。如下

==示例:==

![Graph18](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wbfpwgwpj20ce07m0sx.jpg)



​		

​		其实我们可以发现横向边要么是树与树之间的横跨，要么是子树与子树之间的横跨，比如结点2号和结点3号单个结点的子树，通过一个横向边(2,3)相连。

​		无向图中，可能会有些模糊性，这是因为$(u,v)$和$(v,u)$是同一条边，我们一般使用在深度优先搜索算法中第一次探索到边$(u,v)$时去定的类别作为其真正的类别。下面我们来证明在对无向图G进行深度优先搜索时，从来不会出现前向边和横向边。

==定理4:==在对==无向图==$G$进行深度优先搜索时，每条边要么是树边，要么是后向边，

==证明:==设$(u,v)$是$G$的任意一条边。不是一般性，假定$u.d<v.d$。那么因为结点$v$在结点$u$的邻接链表中。搜索算法将在完成结点$u$的处理之前。必定会发现然后完成对结点$v$的处理。如果算法第一次探索边$(u,v)$，其方向是从结点$u$到结点$v$，则结点$v$在该时刻之前为白色。这种情况下为树边，如果第一次探索这条边$(u,v)$是反方向（$v$到$u$)，那么$(u,v)$为一条后向边。

​		在有向图中我们还是只会出现树边的，因为后向边都会被我们排除掉。

## 五、有向图的拓扑排序(Topological sort)

​		我们日常生活中做一些事情都是有顺序，比如早上起来先刷牙，然后吃饭，然后再到图书馆去学习等等。这些所做的的是都可以描述为一个线性的序列，它可以用==有向无环图==来表示，例如下面的图展示了weekie穿衣服的过程。

==示例:==

![Graph19](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wcodkow7j20cz06hdg1.jpg)



​																										图4



​		上图中也表明了其时间戳，我们从内衣开始进行深度优先搜索。其中箭头表示先完成了什么，然后再能干什么这种次序。==拓扑排序==就是在有向无环图中，使结点能以一种线性次序排列，其中排在前面的必须先完成，排在后面的才能进行。下面给出正式定义

==定义:==对于一个有向无环图$G=(V,E)$来说，其拓扑排序是$G$中所有结点的一种线性次序，该次序满足如下条件:如果图$G$包含边$(u,v)$，则结点$u$在拓扑排序中处于结点$v$的前面(如果图$G$包含环路，则不可能排出一个线性序列)。可以将图的拓扑排序看作是将图中的所有结点在一条水平线上排开，**图中所有有向边都是从左指向右**。

​		我们对图4在一条水平线上展开，如下图所示:

==示例:==

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wd6l1p2bj20nm03lt8x.jpg)



​																										图5



​		知道了定义，并且在有DFS的基础上，这个算法就已经可以较好的实现了，我们注意到，DFS中记录的时间$v.f$是完成对结点访问的时间，我们知道访问的时间越早的结点，其越在深度优先树的最底端。并且其在线性序列中牌的越后面。正如上面图5所示格子衫是最先完成访问的。因此越早访问的放在越后面。我们只需要对DFS算法稍作修改即可，每次访问完结点后，将这个结点**插入到一个链表的头部**，然后最终返回这个链表，就是该图拓扑排序的结果。

​		但需要注意一点的是，起始搜索结点(或中间过程中选择相邻结点的算法不同)选择的不同会导致链表中的顺序会不一样，图5起始搜索结点是内衣，换做其他其实结点就可能产生不同的顺序，例如我以袜子为DFS的起始搜索结点，并将其从水平相展开，其链表存储的顺序也可能是像下面这样子的:(这里用也可能是因为在中间过程中选择相邻结点那里可能产生不同，例如内裤的相邻结点由鞋和秋裤，我可以先选秋裤，也可以先选鞋)。

==示例:==

![Graph21](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wg52fu5cj20n7033aaa.jpg)



​		以上也是一个符合要求的对于图4的拓扑排序。虽然说会生成多种结果，但是仔细观察有一点是不会变的，比如秋裤永远不可能在链表中出现在内裤的前面。也就是说虽然有不同的结果，但这些结果都保证了在箭头后的结点永远只可能在箭头(有向图的箭头)前结点的后面，也就是定义。

==实现代码:==

​		实现代码很简单，DFS上稍作修改即可。		

```c++
std::list<int> adjacencyList::DFS()
{
    std::vector<int> stateList(_array.size(), 0);//状态为0表示为白色，1表示为灰色，2表示为黑色
    std::vector<std::pair<int,int>> timeList(_array.size(), {0,0});//记录每个结点的时间戳
    for (auto i = _freeSerialNum.begin(); i != _freeSerialNum.end(); i++)//刚开始我们扫描空闲编号的结点，并将其对应状态置为黑
    {
        stateList[*i] = 2;
    }
  	std::list<int> result; 
    int time = 0;
    //生成森林。
    for (size_t i = 0; i < _array.size(); i++)
    {
      	if(stateList[i] == 0)
        {
          	DFS(i, time, stateList, timeList, result);//调用重载函数开始生成不同的深度优先搜索树
        }
    }
  	return result;
}
void adjacencyList::DFS(int a, int & time, std::vector<int> & stateList, std::vector<std::pair<int,int>> & timeList, std::List<int> & result)
{
    time += 1;//时间加1，为搜索时间
    timeList[a].first = time;//记录v.d
    stateList[a] = 1;//变为灰色，说明被搜索到了(被发现了)
    Node* targetNode = _array[a]->next;
    while(targetNode != nullptr)
    {
        if (stateList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , stateList, timeList, result);//递归调用
        }
    }    
    //以下为回溯过程中的代码
    std::cout << a << " ";//打印该结点编号。
  	result.push_front(a);//将结点编号加入链表
    stateList[a] = 2;//置为黑色
    time += 1;//时间戳加1
    timeList[a].second = time;//记录该时间戳为v.f
}
```

​		上面的代码只是在原来DFS的代码上做了部分修改，其实我们可以不用记录==时间戳==，只需要状态列表即可，前面记录时间戳只是为了方便说明次序。但在后面计算有向图强连通分量时，我们可以看到时间戳有很大的用处。以上代码没出现在源代码中。

==时间复杂度:==和DFS一样，为$\Theta(V+E)$。

​		我们下面证明拓扑排序的正确性。

==引理4:==一个有向图$G=(V,E)$是无环的，当且仅当对其进行深度优先搜索后不产生后向边。

==证明:==典型的充要条件证明题。首先通过反证法证明充要性，假设无环图$G$存在一条后向边$(u,v)$，则在深度优先森林中，$v$就是$u$的祖先，而这条边是从$u$指向$v$的，说明$v$到$u$存在一条路径，$u$到$v$也存在一条路径。这形成了环，这与无环图的假设不相符，因此无环图不产生后向边。

​		其次证明必要性。深度优先搜索不产生后向边的图是无环的，还是利用反证法，假设图$G$中存在1个环路c，我们接下来只需要证明深度优先搜索产生一条后向边即可完成证明。设$(u,v)$是环路$c$上的一条边，在时刻$v.d$，环路$c$中的结点形成一条从结点$v$到结点$u$的全白色结点路径。根据白色路径定理，结点$u$将在深度优先搜索中称为结点$v$的后代，因此$(u,v)$是条后向边。

==定理5:==上述代码中的拓扑排序算法生成的是有向无环图的拓扑排序。

==证明:==假定我们使用DFS，来计算每个结点的完成时间。我们只需要证明对于任意一对不同的结点$u,v\in V$，如果图$G$包含一条从结点$u$到结点$v$的边，则$v.f<u.f$。考虑深度优先搜索中所探索的任意一条边$(u,v)$。当这条边被探索时，结点$v$不可能是灰色，那样的话$(u,v)$解释一条后向边，那么根据引理4，其必定是有环的。所以结点$v$只可能是白色或者是黑色，，如果结点$v$为白色，那么其为结点$u$的后代，根据深度优先搜索算法，必然有$v.f<u.f$。如果结点$v$为黑色结点，那么其已经被访问，但此时此刻，结点$u$还未被访问，所以必然有$v.f<u.f$。得证。

## 六、有向图的强连通分量算法

​		我们之前介绍了图的连通性，而有向图的强连通分量也是和连通性密切相关的。我们首先介绍什么是强连通分量。在许多有关有向图算法运行之前，几乎都要求得其强连通分量，因此这很重要。

### 1 强连通分量

​		在介绍强连通分量之谦，我们首先理解一下什么是无向图的连通分量。

#### 1.1 无向图的连通分量

​		我们之前介绍过，如果无向图中的每个顶点都可以由图中其他的结点达到，那么我们说这个无向图是连通的。那么如果一个图是不连通的，那么我们一般会考察它的==子图==的连通性。一个图肯定是有有限个连通的子图组成，子图数量最小值为1，也就是图本身就是连通的，这个数量的最大值为结点数量，也就是图中没有一条边，每一个结点单独成为一个图。我们将无向图中这些连通的子图称为==连通分量==。用离散数学中的话术来说，无向图中的连通分量是“互相可达”关系下顶点的等价类。

​		举个例子，下面无向图中连通分量为$\{0,1,4\},\{2,5\},\{3\}$

==示例:==

![Graph22](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wj8zpoc9j209b050wee.jpg)



#### 1.2 有向图的强连通分量

​		有向图的强连通分量的理解也和无向图的连通分量类似，我们知道如果有向图中的每个顶点都可以由图中其他所有结点通过有限部到达，我们说这个图是强连通的。我们同样可以将一个有向图分成一个有限的强连通的子图，我们把这些子图成为==强连通分量==。

​		举个例子，下面有向图中的强连通分量有$\{0,1,3,4\},\{2\},\{5\}$

==示例:==

​                                                          		![Graph23](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wjnm5h44j209b05at8n.jpg)

​																																																										

​																								图6

​		由于只有$(5,2)$没有$(2,5)$,所有结点2和结点5只能是两个单独的强连通分量。我们一般用符号$SCC$表示强连通分量。下面我们正式开始研究如何计算连通分量。

### 2 Tarjan强连通分量算法(Tarjan's strongly connected components algorithm)

​		这个算法是比较巧妙的，并且可以在线性时间内完成，在进行此算法之前，我们先考虑几个简单情景。

​		我们首先考虑如下情景，如果我们进行DFS的时候如果遇到一个结点，其没有相邻结点。也就是说其无结点可以搜索了，例如上面图6中的二号结点就是这样的。那么我们可以确认，这个**结点必定是该图的强连通分量**，并且这个强连通分量只含有这一个结点。这显然是正确的，单个结点可以是一个强连通分量，其次其没有相邻结点，只可能会有指向它的结点，但是它和指向它结点的结点并不是强连通。于是我们得出结论:**(1)在有向图中，一个没有相邻结点的结点必然是图中单独的一个强连通分量。**

​		现在考虑这样一个事实:图中的环路必定是图中某个强连通分量是一部分或者是全部。要理解这个得理解在环中的所有的结点都是互相可达的，这符合强连通的定义，因此我们可以知道==环必定是强连通的==。其次说是一部分或者是全部，我们可以以上面的图6为例，其中$\{0,1,3\}$是一个环，$\{3,4\}$也是一个环，它们有着公共的结点为3号结点。两个环内部的结点肯定是可以互到达问到的，然而它们之间可以通过"3"这个媒介互相到达对方的结点，因此我们说$\{0,1,3,4\}$为一个强连通分量。于是我们又能得出一个结论:**(2)一个环如果与另一个环有公共的结点，那么这两个环必定在同一个强连通分量上。**这个结论还能推广，按照离散数学上的话说，这个性质具有传递性，假如一个环$c_1$和另一个环$c_2$具有公共结点，环$c_2$和另外一个环$c_3$也有公共结点，那么我们可以判定$c_1$和$c_3$也在同一个强连通分量上，实际上三只都在同一个前强连通分量上。如下图就是一个典型的示例:

==示例:==

![Graph24](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wp5txugdj20cy06a74m.jpg)



​		上图中有3个环，每个环用不同的颜色标注，其中$c_1$和$c_2$有公共结点2，$c_2$和$c_3$有公共结点3。三个环中的所有结点组成了一个强连通分量。

​		我们再次考虑一个事实:如果一个结点**不在环上**，那么其必然是在一个只有自己一个结点组成强连通分量上。这个我们可以由反证法轻松证明，假设一个结点$u$不在环上，另一个结点$v$和其处在同一个强连通分量上，那么根据强连通量的定义，$u$和$v$是互相可达的，我们可以通过序列$\{u\dots v\}$访问到$v$，然后再通过序列$\{v,\dots,u\}$访问到$u$，$u$必然在一个环上(这么说有点不准确，原因在于不同的环可以像上述结论(2)一样连在一起，从而达到$u$和$v$互相可达，但这还是说明了$u$在环上)。因此我们得到结论:**(3)如果一个结点不在环上，那么其必然是在一个只有自己一个结点组成强连通分量上，这相当于是在说如果一个结点数大于等于2的子图为强连通分量，其必须存在环。**

​		有了以上的三个结论，我们现在看下如何实现这个算法，我们希望沿用我们DFS算法完成这个过程。因为寻找强连通分量必然涉及到遍历，而DFS可以用来检测环(这里你应该回忆起后向边的判断，如果遇到的结点$v$为灰色的，那么$(u,v)$为为一个后向边，根据引理4，我们可以知道，带有后向边的图是有环的)。我们先考虑像下面一样的算法，看看是否能解决问题。

#### 2.1  一个简单的尝试

​		我们仿照DFS的时间戳记录的方式，记录两个变量第一个变量和$v.d$含义相同，我们就用$v.d$代表第一次发现结点的时间戳。我们另外一个变量记录该结点当前所处在的强连通分量，我们用$v.c$表示。我们和`timeList`一样用数组存储。(下面介绍的算法是错误的，但我觉得这对后面正确的算法会有一些帮助)

​		我们和DFS一样开始遍历。起初，**在没遇到环之前**，我们第一次遇到每个结点(也就是白色结点)，我们更新$v.d$，==并令$v.c=v.d$==。这里这么做是因为**结论(3)**。每一个结点不再环上，那么其必然是在一个只有自己一个结点组成强连通分量上。我们在没遇到环之前，路径上的每个结点都满足结论(3)，所以他们处在不同的强连通分量上，我们用其发现它们是的时间戳区分它们的强连通分量(因为它们第一次发现的时间戳互不相同)，我们以图6为例，假设探索顺序为0->1->3，那么探索到3时的$v.d$和$v.c$，应该像下图这样:

==示例:==

![Graph25](https://tva1.sinaimg.cn/large/e6c9d24egy1h0wqxp9fwgj209w05uweh.jpg)

​			

​																													图7

​		

​		如上图所示，$v.d$和$v.c$标在结点的左上角。未探索的结点标号为$0/0$。

​		如果我们遇到了环(这个可已通过`stateList`去判定，这里沿用了DFS中设定的数组)。那么我们假设第二次遇到的灰色结点为$v$，当前结点为$u$，==我们令$u.c=v.c$==。这么做的原因是因为结论(2)中用到的事实:图中的环路必定是图中某个强连通分量是一部分或者是全部。我们可以直接判定这个环路上的所有结点都在同一个强连通分量上，我们用第二次遇到的灰色结点$v$的强连通分量的编号代表这个强连通分量，所以又这个赋值操作。读者可能会好奇，那么其他和$u$以及$v$处在同一个环路上的结点怎么办，这里你需要注意$u$的其他处在环路上的那些祖先结点，我们会在回溯的时候访问它们(DFS遍历的特点，不懂得话看后面代码，也可以看在讲DFS那里代码的第29行，那个递归调用回来后，我们再改变其$u.c$)，这和在DFS中是一样的。我们本质上就是在用DFS遍历。

​		如果在路中我们遇到了一个没有任何相邻结点的结点，根据结论(1)，它直接为一个单独的强连通分量。

​		然后在回溯过程我们需要做如下的工作，检查其相邻结点$v$的$v.c$，如果$v.c<u.c$，那么我们令$u.c=v.c$ ，这么做是因为我们刚开始没遇到环之前我们有$u.c=u.d$，$v.c=v.d$ ，且$u.d<v.d,u.c<v.c$。现在回溯时$v.c$比$u.c$小了，说明中途必然遇到环了。那么$u$必然也在环上，要理解这个你得知道DFS生成的深度优先树，每个结点最多只有一个父结点。不存在另一个$v$的父结点$x$使得$x$和$v$在环上，而$u$不在环上。最后，在结点$u$的相邻结点全部访问完之后，我们将这个结点编号加入到其编号为$u.c$所在的强连通分量里去。持续这样处理，直到我们访问完所有结点。

​		较为可惜的是这种想法一个问题是它并不能找到一个完整的强连通分量，我们仍然以图6为例，如下图所示:

==示例:==

![Graph26](https://tva1.sinaimg.cn/large/e6c9d24egy1h0yjpgok3vj20n4169juv.jpg)



​		在上面的图中，我们从图7的状态开始选择不同的结点开始探索，我们发现选择不同的路径最后的结果可能是不一样的，显然上图中左边的路径是正确的，它找到了正确的强连通分量。我们考察一下为什么右边的会产生错误，其原因在于$\{0,1,3,4\}$里有两个环，我们知道一个环必然是一个强连通分量，但结论(2)中的事实也说了一个环是一个强连通分量的一部分或者全部，以上就是这种情况。4号结点在探索完自己最后一个相邻结点的时候，其$v.c$已经确定下来了，我们知道它的$v.c$应该就是3号结点的$v.c$，但$3$号结点的$v.c$在后面发生了变化。所以在才导致了这种情况。也就是说这个算法并不能找到完整的强连通分量。当然我们也可以在后面对一些不完整的强连通分量进行合并来达到此目的(可以这么做，如果一个结点的$v.c$等于另外一个结点的$v.d$，那么其必然处在同一个强连通分量)，但我们还是更希望能找到在一次DFS遍历中找到所有完整强连通分量的算法。上述算法失败的原因主要在于它并不能很好的标记结论(2)中所有含有公共结点的环，因为每个含有公共结点的环中的结点应该有相同的$v.c$。	

#### 2.2 正确的实现

​		其实上面的问题主要在于我们如何找到一个完整的强连通分量，所以我们需要找到一个能确定已经找到一个完整强连通分量的方法。我们主要考察3种边:树边，后向边和横向边。由于前向边对于查找强连通分量是无影响的，所以我们不考虑(提示:如果有大于2的结点在同一个强连通分量上，其中存在前向边，那么前向边必然会在这个强连通分量中形成一个较小的强连通分量，且这个连通分量被包含在较大的连通分量中)。

==引理5:==让$v$和$w$为两个处在相同强连通分量的结点，设$F$为DFS生成的深度优先森林，那么我们说$v$和$w$有公共的祖先$u$在深度优先森林$F$中。更进一步来讲，如果$u$是$v$和$w$所有公共祖先中$u.d$最大的结点，那么我们必然有结点$u$和结点$v$以及结点$w$处在同一强连通分量中。

==证明:==当我们的$v$或者$w$为$u$时，这个结论显然是成立。现在我们考虑结点$u$既不是$w$也不是$v$的情况。不失一般性，我们假设$v.d<w.d$，也就是结点$v$比结点$w$先发现。首先考虑，如果$w$在$v$的子树中，那么我们必然可以得到$u=v$ ，因为$v$和$w$的公共祖先为$v$。由前面可以知道，这种情况是成立的，我们考虑别的情况。$w$不在$v$所处在的子树中，根据强连通分量的定义，我们有$v\stackrel{*}{\Rightarrow}w$，这个符号的意思是我们结点$v$经过至少一条边可以到达结点$w$。同样的，我们有$w\stackrel{*}{\Rightarrow}v$。现在假设一个以$u$为根结点的树$T_u$，其是包含了路径$v\stackrel{*}{\Rightarrow}w$上所有结点的最小的树(也就是包含路径上所有结点且$u.d$最大的树)。这样的树是必然存在的。这是由于这条路径$v\stackrel{*}{\Rightarrow}w$上**一定存在至少一条后向边**，这是因为$v.d<w.d$，而这条路径需要连接两棵不同的子树($v$和$w$分别所处在的子树)。肯定不可能出现$(v,w)$这样的边，因为这不满足横向边的条件，如果有的话$w$必然在$v$的子树上。进一步的在$v$的子树上的所有结点都不可能通过一条横向边到达$w$，因为子树上的结点的$x.d<w.d$(深度优先搜索的过程可得)。所以这条路径上必然存在一条后向边，它会到达$w$的祖先，然后通过$w$的祖先连接到$w$。再者我们可以知道这个祖先也必然是$v$的祖先，如果不是$v$的祖先，那么必然会在$v$的子树上，那就会得到$w$也在$v$的子树上，这和我们之前假设的$w$不处在$v$所处的子树中相矛盾，所以$v$和$w$必然有公共的祖先在深度优先森林中。

​		现在我们进一步证明如果$u$是结点$v$和结点$w$的所有公共祖先中$u.d$最小的，且$w$和$v$处在同一个强连通分量上，那么$u$也在和他们一样的强连通分量上。要证明这个我们只需要确认$u$在路径$v\stackrel{*}{\Rightarrow}w$上即可。在上面的证明中，我们已经知道了这个公共祖先$u$必然会在路径上经过，这样我们就有$v\stackrel{*}{\Rightarrow}u$，又因为$w\stackrel{*}{\Rightarrow}v$，所以有$w\stackrel{*}{\Rightarrow}u$，再者$u$是两者的公共祖先，所以可以到达$u,w$，因此得证。

==推论3:==设$C$为图$G$中的一个强连通分量，那么$C$中的结点定义了一棵在深度优先森林的一棵深度优先树的子树，我们把这棵子树的根结点称作该强连通分量的一个**根结点**。

​		得出了这个结论实际上简化了我们寻找强连通分量的过程，我们只需要找到该强连通分量的**根结点**，接着由推论3我们知道其他和其在同一个强连通分量的结点必然在以这个结点为根的子树中，我们可以用一个栈保存DFS中探索到的结点。然后在回溯过程中，如果当前的即将访问的结点$u$(也就是该结点即将涂黑)为强连通分量的根结点，那么根据推论3，我们知道以其起为根的子树中的结点必然出现在栈中，并且在栈中$u$的上方，我们只要进行持续的弹栈，直到遇到这个根结点，然后把这个根结点弹出，我们就能找到一个完整的强连通分量(弹出的所有结点)。有些读者可能会好奇，如果在这个栈中，某个强连通分量的根结点位置之上出现了别的强连通分量的结点，那是不是就不正确了。但这种情况不可能发生，因为存储在栈中离栈顶较近的位置的结点，其$v.d$必然比存储在离栈顶较远位置的结点的$v.d$较大。而$v.d$较大的会被先访问，那么如果其是某个强连通分量的根结点，它必然会先被弹栈，所以我们可以得到，如果当前访问的结点为某个强连通分量的根结点，那其在栈中的位置的上方就不可能出现别的强连通分量的根结点了，因为其已经被访问并且弹出了，由于整个强连通分量的结点和其根结点一起弹出，所以必然不存在别的强连通分量的结点。并且这能保证找到完整的强连通分量，因为强连通分量的根结点被弹出之前，我们肯定能弹出其余所有何其在同一个分量中的结点(因为其余结点都在栈中相对于根结点靠后的位置)。为了具体说明我们找一个较为复杂的例子。

==示例:==

![Graph28](https://tva1.sinaimg.cn/large/e6c9d24egy1h0yu7xk9stj207n07gaa5.jpg)

​		

​																											   图8



​		上面的图看上去有有点乱，假设我们从图8中0开始遍历，我们会生成如下的深度优先森林:

![Graph29](https://tva1.sinaimg.cn/large/e6c9d24egy1h0yuwft6gqj20550a774b.jpg)

​																						

​																											图9

​		我们先不考虑如何确定一个结点是否是强连通分量的根结点，我们对上面的图从0开始进行DFS遍历，并使用栈存储。

==示例:==

​                                                                     ![Graph32](https://tva1.sinaimg.cn/large/e6c9d24egy1h0zsijyfs3j20fp2ian2g.jpg)



​		读者可以验证，上述过程中生成的强连通分量是正确的。我们可以用数组或链表来存储结点。

​		我们现在唯一的问题就是如何确定一个结点是否是其所处的强连通分量的根结点。因此我们需要在探索的过程中和我们之前的尝试一样维护一些信息，是其可以判断一个结点是否是强连通分量额度根结点，我们仍需维护$v.d$,但是我们不能在向之前尝试过程中那样维护$v.c$了，它并不能判断一个结点是否是强连通分量的根，tarjan非常漂亮的给出了我们需要维护的量，我们把它命名为==$v.lowlink$== ，**它的含义是假设某个结点$x$和$v$处在同一个强连通分量中，$v.lowlink$的值为其中最小的$x.d$，$x$可以为$v$**。

==引理6:==假设我们采用了$lowlink$维护信息。那么在一个由图$G$上使用深度优先搜索生成深度优先森林中。结点$v$为$G$其中一个强连通分量的根结点当且仅当$v.lowlink=v.d$。

==证明:==这是一个充要条件证明，首先证明必要性，根据推论5我们知道一个强连通分量中所有的结点必然在以某个结点为根的子树上，那么我们假设根结点为$u$，那么$u.d$必然比一起为根的子树中的所有结点都要小。该连通分量中所有结点的$v.d$均小于$u.d$，$u.d$是这个强连通分量中最小的$x.d$。根据$lowlink$定义，我们有$u.lowlink=u.d$。

​		下面证明充分性，如果强连通分量中的某个结点$v.lowlink=v.d$，我们可以用反证法，如果其不是强连通分量根结点，那么我们可以知道其该强连通分量的根结点$u$必然是其祖先，那么我们必然有$u.d<v.d$，但是根据$lowlink$定义我们知道$v.lowlink$必须是强连通分量中最小的$x.d$.现在$v.d$不是最小，那么违背了条件，所以如果$v.lowlink=v.d$，那么$v$必然是该强连通分量的根结点。

​		我们现在知道了如何判断一个结点是否是其所在的强连通分量的根结点，下面的问题就是我们该如何在DFS中维护这个变量呢？我们之前虽然做了一个不是那么好的尝试，但其中的一些步骤还是具有参考价值的。我们在进行DFS的时候，在没遇到环之前，我们仍然使得$v.lowlink=v.d$ (我们仍需维护$v.d$) 。并将每个结点加入一个栈中。这是因为结论(3)，这些结点暂时都不在环上。于是根据$lowlink$的定义，所以我们这样设置(强连通分量只有结点本身)。

​		其次在遇到环之后，假设当前结点为$v$，下一个结点$w$为之前遇到过的结点且$(v,w)$为后向边($w$为灰色结点)，那么我们就令==$v.lowlink=\min(v.lowlink,w.d)$==。这么做的原因是结论(2)中提到的事实，一个环必然是强连通分量的全部或者一部分，其次是根据$lowlink$的定义，我们取较小的值。

​		然后在回溯的过程中(DFS代码中29行递归调用后)，假设递归调用DFS是处在边$(v,w)$。我们令$v.lowlink=min(w.lowlink,v.lowlink)$，这么做的原因是因为在遇到环之后(或者说处于一个新的强连通分量中)，根据$lowlink$定义之前遍历路径的所有$lowlink$都要产生变化。

​		最后我们在DFS访问结点那个时刻检查当前即将访问的结点是否有$v.lowlink=v.d$ 。如果有，我们则找到了该强连通分量饿根结点，那么其子树中何其处在同一个强连通分量的结点肯定处在栈中，我们创建一个链表或者数组，假设栈中的结点为$x$，我们将其中$v.d\le x.d$的所有结点$x$加入这个链表或者数组，最后这个链表存储了一个完整的强连通分量。我们重复上述几步操作，就能找到所有的强连通分量。

​		我们对上面的深度优先森林中进行$lowlink$编号，如下图所示

==示例:==

![Graph33](https://tva1.sinaimg.cn/large/e6c9d24egy1h0zt643s9dj206v0aswes.jpg)

​			编号左侧为$v.d$右侧为$lowlink$。

==实现代码:==

​		我们任然可以套用DFS的框架实现这个代码，注意下面的代码没有出现在源代码中。

```c++
std::vector<std::vector<int>> adjacencyList::DFS()
{
    std::vector<int> stateList(_array.size(), 0);//状态为0表示为白色，1表示为灰色，2表示为黑色
    std::vector<std::pair<int,int>> timeList(_array.size(), {0,0});//记录每个时间戳，第二个记录lowlink
    for (auto i = _freeSerialNum.begin(); i != _freeSerialNum.end(); i++)//刚开始我们扫描空闲编号的结点，并将其对应状态置为黑
    {
        stateList[*i] = 2;
    }
  	std::vector<std::vector<int> > result;//存储强连通同分量 
    int time = 0;
  	std::stack<int> stack1;//用于存储的栈
    //生成森林。
    for (size_t i = 0; i < _array.size(); i++)
    {
      	if(stateList[i] == 0)
        {
          	DFS(i, time, stateList, timeList, result, stack1);//调用重载函数开始生成不同的深度优先搜索树
        }
    }
  	return result;
}
void adjacencyList::DFS(int a, int & time, std::vector<int> & stateList, std::vector<std::pair<int,int>> & timeList, std::vector<std::vector<int> > & result，std::stack<int> & stack1)
{
    time += 1;//时间加1，为搜索时间
    timeList[a].first = time;//记录v.d
  	timeList[a.second] = time;//记录
    stateList[a] = 1;//变为灰色，说明被搜索到了(被发现了)
  	stack1.push(a);//将该机诶单压栈
    Node* targetNode = _array[a]->next;
    while(targetNode != nullptr)
    {
        if (stateList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , stateList, timeList, result, stack1);//递归调用
          	timeList[a].second = std::min(timeList[a].second, timeList[targetNode->vertex2].second);//取较小值
        }
      	else if (stateList[targetNode->vertex2] == 1)//如果找到灰色结点，说明出现了后向边，说明有环
        {
          	timeList[a].second = std::min(timeList[a].second, timeList[targetNode->vertex2].first);//取较小值
        }
    }    
    //以下为回溯过程中的代码
		if(timeList[a].first == timeList[a].second)//说明找到了强连通分量的根结点，开始弹栈
    {
      	int index = result.size();//记录索引秒变与后面访问。
      	result.emplace_back(std::vector<int>());//添加新的数组用于存储新的强连通分量
      	int temp = stack1.top();
    		do
    		{
          	result[index].emplace_back(temp);
      			stack1.pop();
          	temp = stack1.top();
				}while(timeList[temp].first >= timeList[temp].second);
		}
    stateList[a] = 2;//置为黑色
}
```

​		上面的代码可能$DFS$这个函数的参数有点多，解决函数参数太多有很多种方法，我们可以将DFS递归的形式转换成栈形式，这样里面的大多数参数都能转换成局部变量，其次，我们可以将其中一些变量设为静态变量或者全局变量（不推荐）。

==时间复杂度:==和DFS是一样的为$\Theta(V+E)$。我们额外使用了一个栈去记录，所以空间复杂度略有增加，增加$\Theta(V)$。

​		我们可以证明以上算法是正确的，但在这里不在展开。读者可以参考tarjan在1972年撰写的论文[DEPTH-FIRST SEARCH AND LINEAR GRAPH ALGORITHMS*](https://github.com/tpn/pdfs/blob/master/Depth-First%20Search%20and%20Linear%20Graph%20Algorithms%20-%20Tarjan%20(1972).pdf)主要采用了数学归纳法证明$lowlink$可以被正确的计算。

### 3 Kosaraju强连通分量算法

​		这也是一个较为巧妙的算法，它同样也能在线性时间内完成，但速度较于Tarjan的算法会稍微慢一些。

#### 3.1 有向图的转置

​		这个算法首先需要用到图有向图的转置这个概念，这个和矩阵中的转置有点类似，我们用符号$G^T$表示有向图的转置。

==定义:==对于一个一个有向图$G=(V,E)$，其转置$G^T=(V,E^T)$，其中$E^T=\{(u.v):(v.u)\in E \}$。

​		上述定义中，我们用较为口语化的表述就是，我们将有向图中的所有边经过反向反转得到的新图就是$G^T$。下面我们针对邻接链表实现有向图的转置算法。

​		实现这个算法非常简单，我们首先需要创建和原来图$G$含有相同结点数量不含一条边的图$G'$，然后我们扫描原来的图，针对图$G$中的每一条边$(u,v)$在图$G'$中插入$(v,u)$。重复这个过程直到所有边被插入即可。

==实现代码:==

```c++
adjacencyList adjacencyList::transpose()
{
    adjacencyList temp;
    for (size_t i = 0; i < _array.size(); ++i)
    {
        adjacencyList::insertVertex();//插入结点
    }
    for (size_t i = 0; i < _array.size(); ++i)
    {
        Node* targetNode = _array[i]->next;
        while (targetNode != nullptr)
        {
            temp.insertEdge(targetNode->vertex2, i ,targetNode->weight);
            targetNode = targetNode->next;
        }
    }
    return temp;
}
```

==时间复杂度:==我们需要扫描到图中的所有结点和所有的边，而针对每一条边的插入对于邻接链表来说只需要$O(1)$，所以我们需要$O(V+E)$的时间。

​		其实根据强连通分量的定义·，我们不难发现，**$G^T$的强连通分量和$G$的强连通分量是一样的**，原因在于强连通分量中任意两个结点都是互相可达的，并且其是由有限个环组成，对组成环的边施行转向并不改变连通性。

#### 3.2 分量图

​		接下来我们需要介绍分量图，并且介绍分量图的性质。这将会对后面的算法的实现有很大的帮助。我们用$G^{SCC}=(V^{SCC},E^{SCC})$表示一个分量图。根据tarjan算法中可以得到一个启发，我们可以用一个结点代表一个强连通分量。于是我们得到如下的定义:

==定义:==假定图$G$有强连通分量$C_1,C_2,\dots,C_k$，结点集$V^{SCC}$为$\{v_1,v_2,\dots,v_k\}$，对于图$G$的每个强连通分量$C_i$来说，该集合包含代表该结点分量$v_i$。如果对于某个$x\in C_i$和$y\in C_j$，图$G$包含一条有向边$(x,y)$，则边$(v_i,v_j)\in E^{SCC}$。从另一个角度来看，通过收缩所有相邻结点都在同一个强连通分量中的边，剩下的图就是$G^{SCC}$。

​		我们给出图8的$G^{SCC}$图作为示例:

==示例:==

![Graph34](https://tva1.sinaimg.cn/large/e6c9d24egy1h1018cllkmj20cr0b2dgc.jpg)



​																							图10

​		彩色的结点代表不同强连通分量其中编号可以是任意的，($G^{SCC}$图中)0号结点代表的强连通分量在原来的图$G$中通过边$(1,2)$和结点为$1$的强连通分量相连，二结点为1的强连通分量通过$(4.5)$和$(6.5)$这两条边和2号结点代表的强连通分量相连，这里我们用一条边表示。

​		下面我们会证明分量图的重要性质:**分量图是一个有向无环图**。

==引理7:==设$C$和$C'$为有向图$G=(V,E)$的两个不同的强连通分量，假设有两个结点$u,v\in C$，以及另外两个结点$u',v'\in C'$，如果存在一条路径$u\stackrel{*}{\Rightarrow}u'$，那么必然不可能存在$v'\stackrel{*}{\Rightarrow}v$。

==证明:==我们使用反证法，假设存在$v'\stackrel{*}{\Rightarrow}v$ ，首先由于$C$是一个强连通分量，所以我们可以得到一条路径$v\stackrel{*}{\Rightarrow}u$。同理我们也可以根据$C'$得到$u'\stackrel{*}{\Rightarrow}v'$。于是我们就得到$u\stackrel{*}{\Rightarrow}u'\stackrel{*}{\Rightarrow}v'\stackrel{*}{\Rightarrow}v\stackrel{*}{\Rightarrow}u$这形成了一个环路，根据结论(2)，我们知道处在环路上的结点必然属于同一个强连通分量，然而我们的$C'$和$C$不是同一个强连通分量，这与条件向矛盾，所以必然不可能存在$v'\stackrel{*}{\Rightarrow}v$。

==推论4:==分量图是一个有向无环图。

==证明:==根句分量图的定义我们知道，分量图中连接各个强连通分量的边必然存在于在原来图$G$从一个强连通分量连接另一个一个强连通分量的路径上，由引理7可以知道，每个强连通分量的连接只存在单向的路径，通俗点讲就是强连通分量之间并不是互相可达，要是互相可达，那么其本身就应该组合在一起成为一个更大的强连通分量。所以在分量图中不存在环路。所以得证。

​		下面定义两个概念，我们将结点的发现时间$v.d$和访问(完成)时间$v.f$ 推广到结点的集合上。如果结点集合$U\subseteq V$，则定义$d(U)=\min\limits_{u\in U}(u.d)$，$f(U)=\max\limits_{u\in U}(u.f)$。这两个符号相当于在表示结点集合最小的$u.d$和最大的$u.f$。方便我们证明分量图的其他性质

==引理8:==设$C$和$C'$为有向图$G=(V,E)$的两个不同的强连通分量。假如存在一条边$(u,v)\in E$ ，这里$u\in C,v\in C'$，则$f(C)>f(C')$。

==证明:==这里我们要分两种情况，首先我们考虑$d(C)<d(C')$，这种情况下我们知道$C$中存在一点$w$，它比$C$和$C'$中的所有结点都要早的被发现。当处在$w.d$时，其余结点都为白色结点，根据白色路径定理，并且我们知道有一条连接$C$和$C'$的边$(u,v)$。我们可以知道其余所有结点在深度优先树中都是结点$u$的后代，在根据DFS的搜索特性。我们知道结点$u$必然是最后一个被访问(完成)。那么我们必然有$w.f>x.f$其中$x\in C,C'$且$x\neq w$。所以根据$f(C)$的定义，我们有$f(C)>f(C')$。

​		现在讨论第二种情况。我们考虑$d(C)>d(C')$。说明存在一个结点$w\in C'$，使得它比其他所有结点都要发现的要早。当处在$w.d$时，我们知道除了$w$以外，其他所有结点都为白色结点，格局白色路径定理$C'$中的其余结点必然是$w$的后代。但是根据引理7，我们知道在已经存在一条边$(u,v)$使得$u\in C$，$v\in C'$的情况下，不可能存在$(u',v')$使得$u'\in C',v'\in C$。也就是说不存在从$C'$到达$C$的路径，所以$C$中的就不可能是结点$w$的后代，所以$C$和$C'$处在不同的子树中，由于$C'$代表的子树的根结点$w.d$比$C$代表的子树的根结点的$x.d$要小，所以当访问完所有$C'$中的结点时，$C$中的结点仍然为白色，所以我们必然有$f(C)>f(C')$。

​		如果我们把引理8中的条件的边反响，我们自然能得到一个相反的结论，如下。

==推论5:==设$C$和$C'$为有向图$G=(V,E)$的两个不同饿强连通分量，假如存在一条边$(u,v)\in E^T$，这里$u\in C，$$v\in C'$,$f(C)>f(C')$。

==证明:==我们只需要将引理8中的边$(u,v)$反方向一下就能得出这个推论。这个推论非常重要。我们的算法建立在这个推论上。

#### 3.3 实现算法

​		我们把目光再次放到DFS上(其实我们经过五六节已经大概知道DFS相对于BFS会有更多的用处)。仔细考察我们使用DFS在有向图中必然会生成一个深度优先森林，这个森林里面有着各种各样的强连通分量，而伴随着生成的就是上面介绍的分量图。我们知道分量是一个有向无环图，分量图中的每个结点都代表了一个强连通分量中所有结点的集合。我们再次观察一下图10这个分量图。

==示例:==

![Graph34](https://tva1.sinaimg.cn/large/e6c9d24ely1h1064ujkhij20cr0b2dgc.jpg)



​		我们看到我们用DFS伴随生成的分量图，在这个DFS中我们可以通过一条边访问到另一个强连通分量。但是这条边的存在让我们难以区分不同的强连通分量，我们希望的是不同的强连通分量能是单独的一棵深度优先树(意思就是，DFS生成的深度优先森林，我们希望森林中每个树代表一个完整的强连通分量)，这样我们每次DFS遍历都能找到一个强连通分量。而上图(分量图)中从$0$号结点开始遍历(0->1->2)，显然三个强连通分量在一棵树上，这样会难以区分，所以我们得想一个办法使得每个强连通分量单独在不同的树上。有些读者可能会想上图中如果我们按照(2->1->0)的顺序再进行一次DFS是不是就能生成三棵不同的树了，这个想法初想还是不错的，但是不可行，这是为什么呢，因为我们通过第一次遍历的得出的$v.d$和$v.f$并不能帮助我们确定分量图中最末端强连通分量的结点编号，也就是说我们并不知道起始该遍历的结点。末端强连通分量中的结点不一定就是$v.d$最大或者$v.f$最小的结点。上图中5号结点是$v.f$最小，但是如果把它放在$6$号的子结点上就不满足了。

​		我们转换思路，知道由于$G^T$和$G$是具有相同的强连通分量的，于是我们将上面的所有边反转，在从正向遍历，似乎可以达到同样的效果。但我们和刚才的问题是一样的，我们该怎么遍历，我们能按照之前遍历顺序遍历一边吗(本质上就是$v.d$递增的顺序)，这似乎好像是可行的，但是不正确。我们举个反例，上图中我们如果第一次DFS从编号为2的结点开始遍历，那分量图是不变的，但我们如果在转置后从个结点2号开始遍历是不对的。正确的应该是从$0$开始遍历。其实$0$号结点在不管第一次怎么遍历总是$v.f$最大的结点，正确的方案是按照$v.f$递减的顺序进行遍历，我们通过推论5以更加数理化的角度来观察这是为什么。

​		推论5说明了假如存在一条边$(u,v)\in E^T$ ，$u\in C$，$v\in C'$那么$f(C)<f(C')$。其中$(u,v)$是从$C$到$C'$的边(在$G^T$中)，那么根据引理7我们知道，不可能存在从$C'$到$C$的边，这正是我们想要的，因此我们得从$C'$这个强连通分量开始遍历，而这会推出$f(C')>f(C)$。所以最开始遍历的强连通分量的$f(C)$是最大的(连续推导易得)。回想$f(C)$的定义，我们可以从推出最开始我们需要遍历的强连通分量中必然存在一个$v.f$最大的结点。而遍历完第一个强连通分量后，我们取剩下结点(未遍历过的)中最大的$v.f$开始遍历，这一定是第二个强连通分量中的结点，依次类推。我们的算法就形成了。这个算法需要两次DFS遍历。

==实现步骤:==

​		(1) 首先对图进行第一次DFS搜索，记录每个结点的时间戳。

​		(2) 对图$G$进行转置，然后生成$G^T$

​		(3) 对图$G^T$进行第二次DFS搜索，开始取$v.f$最大的结点开始遍历，每次生成一棵深度优先树后取还未遍历到的结点中$v.f$最大的结点。

​		(4) 最后生成森林中的每棵深度优先树都是一个强连通分量。

==实现代码:==

​		以下代码在源代码中并未出现。在实现的过程中，为了快速找到(3)未遍历结点中最大$v.f$。我们需要做一些额外的措施。如果用数组记录，那么找到下一个最大的$v.f$会浪费时间，我们希望数组中按照$v.f$的大小给每个结点排好序，但我们知道排序的时间复杂度为$O(n\lg{n})$，这显然不是我们期望的。我们不使用`timeList`记录每个结点的$v.f$。而是在第一次DFS中使用==栈==去结点编号。每次我们访问完(完成，也就是结点变黑了)一个结点后，将其压栈中。那么DFS结束后，栈顶到栈底刚好是按照$v.f$递减的顺序排序的。

```c++
std::vector<std::vector<int>> adjacencyList::DFS()
{
    std::vector<int> stateList(_array.size(), 0);//状态为0表示为白色，1表示为灰色，2表示为黑色
    std::stack<int> stack1;//用来记录结点编号的栈。
    for (auto i = _freeSerialNum.begin(); i != _freeSerialNum.end(); i++)//刚开始我们扫描空闲编号的结点，并将其对应状态置为黑
    {
        stateList[*i] = 2;
    }
    for (size_t i = 0; i < _array.size(); i++)
    {
        if(stateList[i] == 0)
        {
            DFS(i, stateList, timeList);//调用重载函数开始生成不同的深度优先搜索树
        }   
    }
  	adjacencyList  temp = transpose();//生成转置图 
  	std::vector<std::vector<int>> result;//用来记录强连通分量
  	stateList.clear();//stateList清0
  	while(!stack1.empty())//下面是第二遍DFS。
    {
       	while(stateList[stack.top()] != 0)//去除已经遍历过的结点
        {
          	stack1.pop()；
        }
        result.push_back(std::vector());//创建一个新的强连通分量集合，使用vector的默认构造函数
      	DFS(stack1.top(), stateList, result);//
    }
  	return result;
}
//以下是第一次DFS用到的函数
void adjacencyList::DFS(int a, std::vector<int> & stateList, std::stack<int> & stack1)
{
    stateList[a] = 1;//变为灰色，说明被搜索到了(被发现了)
    Node* targetNode = _array[a]->next;
    while(targetNode != nullptr)
    {
        if (stateList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , stateList, stack1);//递归调用
        }
    }    
    //以下为回溯过程中的代码
    stateList[a] = 2;//置为黑色
  	stack1.push(a);//压栈
}
//以下是第二次DFS用到的函数
void adjacencyList::DFS(int a, std::vector<int> & stateList, std::vector<std::vector<int>	> & result)
{
    stateList[a] = 1;//变为灰色，说明被搜索到了(被发现了)
    Node* targetNode = _array[a]->next;
  	result.back().push_back(a);//树中的所有结点都在强连通分量中，因此在这里就可以直接加入
    while(targetNode != nullptr)
    {
        if (stateList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , stateList, stack1);//递归调用
        }
    }    
    //以下为回溯过程中的代码
    stateList[a] = 2;//置为黑色
}
```

​		我们在原有的DFS基础上增加了一个重载函数达到了我们想要的算法。

==时间复杂度:== $\Theta(V+E)$。

==定理6:==上述算法能正确计算有向图$G$的强连通分量。

==证明:==我们采用数学归纳法，我们只需要归纳我们第二次DFS生成的每一刻深度优先树都是强连通分量即可，我们假设第二遍DFS生成的前$k$棵深度优先树都是强连通分量。当$k=0$时结论必然成立。

​		现在我们在假定前$k$棵树都为强连通分量饿情况下，我们考虑第$k+1$棵树是否是强连通分量。假设第$k+1$棵树的根结点为$u$，$u$处在强连通分量$C$中，根据我们算法中第二次DFS的遍历顺序，对于我们之后访问的强连通分量$C'$。我们有$u.f=f(C)>f(C')$ ，根据归纳假设，我们在访问结点$u$时，其余何其处在同一个强连通分量的及诶单必然为白色，然后根据白色路径定理，我们可以得出和$u$处在同一个强连通分量的结点必然为结点$u$的后代。接着我们需要证明处在其他强连通分量中的结点不是结点$u$的后代，由推论5，我们知道当$f(C)>f(C')$时，不存在一条从$C$通往$C'$的路径，因此那么些还未遍历的强连通分量$C'$中的结点必然不可能出现在$u$后代中，所以这个深度优先树刚好包含了所有在强连通分量$C'$中的结点。因此得证。

### 4 Gabow强连通分量算法

​		这是我们介绍的最后一个有关强连通分量的算法，它的思想是基于路径的深度优先搜索。

​		在深度优先搜索中，我们不断地从一个结点下降到另一个结点，这个过程在之前的讲述之中会生成一条白色路径。我们下面考察如何在这条路径上寻找强连通分量。我们仍然以图8的图作为例子进行讲述。为了方便起见，这里再次给出图8，以及其对应从0开始搜索的深度优先树。

==示例:==

![Graph28](https://tva1.sinaimg.cn/large/e6c9d24egy1h13lh3huhpj207n07gaa5.jpg)



![Graph29](https://tva1.sinaimg.cn/large/e6c9d24egy1h13lijvu2ij20550a774b.jpg)

​																					                  图 11

​		

​		根据Kosaraju算法中讲述的分量图，我们可以知道每个有向图都有其对应的分量图，分量图中的每个结点是属于同一个强连通分量结点的集合。根据这个思路，考察我们从0开始到7时生成的0->1->7的路径，下一个将搜索到的结点为已经成为灰色结点的0，我们说这时候形成了一个环。根据结论(2)中的一个事实，我们知道一个环必然是强连通分量或者其强连通分量的一部分，因此我们可把这个环路"压缩"成一个结点(类似于分量图中的一个结点，但这个结点可能并没有包含完整的强连通分量)。其次，如果我们路径上最后一个结点(这个结点可能时"压缩"后的结点)没有任何通往其他任何结点的路径了，那么根据结论(1)，那么我们可以知道这个结点只能单独成为一个强连通分量，我们可以将其从路径上直接“删除”。我们似乎只需要通过以上两个结论就能找到强连通分量了。我们从最开始路径只有起始搜索结点，在DFS中不断向路径根据路径最后的结点加入边。并根据情况进行压缩或者删除，直到最后路径为空时，我们就能确定找到强连通分量了。一个"压缩"的结点展开就是一个完整的强连通分量。我们以上面的图11举例:

==示例:==

![Graph35](https://tva1.sinaimg.cn/large/e6c9d24egy1h14jnvdjrjj20mj1een12.jpg)

​		可以看出这个想法是正确的，但又应该如何实现呢，其实其中较难实现的就是如何将所有结点压缩成一个“结点”，也就是说我们如何用一个结点表示一个结点的集合。如果你熟悉并查集，那么你大概率会想用并查集去完成这个算法，使用`Union`将不同的点集合成一个点，我们可以用一个栈存储路径，我们探索路径上最后一个结点的边时，如果这条边指向了路径中已经存在的结点。那么我们就不断的弹栈，直到找到那个路径中已经存在的结点。弹栈的过程中先使用`find`找到结点所在的集合(路径中的结点可能是已经被压缩过的)，然后使用`Union`将结点合并。为了方便，我们可以使用结点集合中的$v.d$最小的结点作为代表结点，这样做的目的在于压缩结点的结点集$v.d$最小的结点必然最晚访问(完成)，而我们要确定一个"压缩"后的结点是否已经没有通向别的结点的路径了，只需要检查$v.d$最小的结点是否访问完即可，因为其访问完成，说明其所有相邻的结点也已经访问完成了，所以也就说明这个"压缩"后的结点没有其他路径可以访问了。可惜的是，上述过程并不能在我们期望的线性时间内完成，即使是在经过路径压缩后的并查集，我们需要一个更加快速的算法。

​		这就需要要我们使用一个更好的方式表示这个"压缩"的结点。我们似乎并不需要真正的使用一个并查集表示这个"压缩"的结点，因为我们发现如果这个强连通分量中$v.d$最小的结点完成了访问那么我们说这个完整的强连通分量已经寻找完毕。我们**使用一个栈$S$保存经过的路径**，然后**使用另一个栈B在DFS中保存每个强连通分量中$v.d$最小的结点**。然后在DFS回溯的过程中，每访问(完成，结点变为黑色)一个结点，我们检查其是否为栈$B$的栈顶，如果是我们就持续对栈$S$弹栈，直到遇到当前访问完的结点，弹出来的结点就是和栈$B$栈顶结点处在同一个强连通分量的结点。然后我们对栈$B$弹栈，表示当前强连通分量已经访问完成。我们持续这个操作，直到最后栈$B$和栈$A$最后都为空。栈$B$中存储的本质上就是含有"压缩结点"结点路径，其实讲当前栈$B$中的所有“压缩"结点展开就是当前栈$S$中的结点。

​		但我们还有个小细节我们需要考虑，那就是一个代表压缩结点的最小$v.d$结点可能在DFS中发生变化，我们考虑如下图所示的情景。

==示例:==

![Graph36](https://tva1.sinaimg.cn/large/e6c9d24egy1h14k12pxezj20880faq38.jpg)

​		这种情况下，原本3处在压缩结点1的结点集合中，但由于3还有一条指向0的后向边，导致新的压缩结点变为0不再是原来的1了，这其中的原因在于1号结点的$v.d$<0号结点的$v.d$。

​		所以我们需要一种机制去解决这种情况。根据上面的图我们可以发现一个"压缩"结点的代表结点会发生变化，主要是由于$v.d$的变化，但只能往变小的方向发展，因此我们可以知道，新的压缩结点的代表结点必然在栈$B$中当前压缩结点的前面。假设当前结点为$u$，我们探索到的已经发现的结点$v$以及其发现的时间$v.d$，我们只要对栈$B$不停地弹栈，直到遇到第一个结点$x$，使得$x.d\le v.d$。新结点$x$就成为新的压缩结点的代表结点，这个操作是正确的，因为弹栈的过程中我们绝对不会遇到一个完整的强连通分量(含有完整强连通分量的压缩结点)。简单证明一下为什么是正确的，首先，我们注意到$x.d<u.d$，并且当处在$u.d$时，结点$x$仍然未完成访问，根据定理2，我们必然有区间$[x.d,x.f]$将区间$[u.d,u.f]$包含在内。所以根据推论2我们知道$u$是$x$的真后代(也可以直接用白色路径定理)，我们有$x\stackrel{*}{\Rightarrow}u$ ，现在我么有通过$u$发现了结点$v$，当$v.d=x.d$时，也就是说$v$就是$x$。那么我们有$u\stackrel{*}{\Rightarrow}v\equiv u\stackrel{*}{\Rightarrow}x$ 。路径中所有结点形成了环路成为了一个新的压缩结点(新的强连通分量)，所以中间压缩结点代表的强连通分量必然是不完整的。其次当$v.d\neq x.d$ ，我们知道$v$必然在$x$所代表的强连通分量上($x$为栈$B$中的压缩结点)，这是因为我们上面提到了$x$是第一个$x.d<v.d$的结点，因为$v$不在栈$B$中，那么其必然是在某个压缩结点所代表的强连通分量中，而这个压缩结点的$x.d$要比$v.d$要小，这是我们之前提到的。既然$v$必然在$x$所代表的强连通分量上，那么我们必然有$v\stackrel{*}{\Rightarrow}x$，然后又因为$u\stackrel{*}{\Rightarrow}v$，所以我们有$u\stackrel{*}{\Rightarrow}x$。因此，依然形成了一个dai路，所有弹栈的过程中我们遇到的压缩结点都是不完整的强连通分量，所以这些在$x$之后的压缩结点和$u$以及$x$组成了一个更大的强连通分量，形成新的压缩结点为$x$。

​		现在我们解决了搜索过程中可能的压缩结点的$v.d$变化的问题，现在我们就可以进行这个算法，我们需要两个栈，以及一个记录每个结点$v.d$的数组`timeList`。

==实现步骤:==

​		我们借助DFS的框架完成这个算法

​		(1) 在DFS搜索的过程中，我们将遇到每一个白色结点都加入栈$S$，同时也加入栈$B$。

​		(2) 如果遇到灰色结点$v$，假设当前结点为$u$，说明$v$在栈$S$中比$u$先入栈。那么此时$u$所处在的压缩结点(栈$B$的栈顶)可能会变化，我们对栈$B$持续弹栈，直到栈顶的结点$x$满足$x.d\le v.d$。

​		(3) DFS回溯过程中访问结点时，如果当前访问完后的结点恰好为栈$B$的栈顶结点$x$，我们对栈$S$持续弹栈，直到栈$S$的栈顶结点为$x$。然后把$x$也弹掉，栈$B$中也弹出$x$。弹出的结点即为图$G$中的一个完整的强连通分量，我们可以用一个数组或者链表接收。

​		(4) 重复上述所有的过程，直到DFS完成。(DFS完成时，两个栈都应该是空的)。

==实现代码:==

​		以下代码并未出现在源代码中，因为其本质上仍然是在DFS的基础上进行修改。这里我们稍作改动，我们其实可以不用使用`stateList`去专门标记结点的状态，其实一个改版`timeList`已经给予了我们足够的信息去判断颜色了，改版的`timeList`只记录一个时间戳，不再对$v.d$和$v.f$加以区分，探索时更新一次，访问完成时更新一次。假设结点$v$，当`v.timeList=0`时，这个结点必然为白色结点，当`0<v.timeList<=|V|`时，其必然为灰色结点。当`v.timeList>|V|`时必然为黑色结点(这个较好证明，不再验证)。

```c++
std::vector<std::vector<int>> adjacencyList::DFS()
{
    std::vector<int> timeList(_array.size(), 0);//记录每个结点的时间戳
    for (auto i = _freeSerialNum.begin(); i != _freeSerialNum.end(); i++)//刚开始我们扫描空闲编号的结点，并将其对应状态置为黑
    {
        timeList[*i] = -1;
    }
  	std::stack<int> stack1;//栈S
  	std::stack<int> stack2;//栈B
  	std::vector<std::vector<int, int>> result;
    int time = 0;
    //生成森林。
    for (size_t i = 0; i < _array.size(); i++)
    {
        if(timeList[i] == 0)
        {
            DFS(i, time, timeList, stack1, stack2, result);//调用重载函数开始生成不同的深度优先搜索树
        }   
    }
  	return result;
}
void adjacencyList::DFS(int a, int & time, std::vector<int> & timeList, std::stack<int> & stack1, std::stack<int> & stack2, std::vector<vector<int>> & result)
{
    time += 1;//时间加1，为搜索时间
    timeList[a] = time;//记录v.d
  	stack1.push(a);//加入栈S
  	stack2.push(a);//加入栈B
    Node* targetNode = _array[a]->next;
    while(targetNode != nullptr)
    {
        if (timeList[targetNode->vertex2] == 0)//先判断是否是白色，只有是白色我们才可以搜索它
        {
            DFS(targetNode->vertex2, time , timeList, stack1, stack2, result);//递归调用
        }
        else if(timeList[targetNode->vertex2] > 0 && timeList[targetNode->vertex2] <= _numOfVertex)//灰色结点
        {
          	//下面对栈B持续弹栈
          	while(timeList[stack2.top()] > timeList[targetNode->vertex2])
            {
               stack2.pop();
            }
        }
    }    
    //以下为回溯过程中的代码
  	if(a == stack2.top())//如果恰好为栈B的栈顶结点
    {
      	result.emplace_back(std::vector());//创建一个存储强连通分量的集合
      	while(stack1.top() != a)
        {
          	result.back().emplace_back(stack1.top());
          	stack1.pop();
        }
      	result.back().emplace_back(a);
      	stack1.pop();
      	stack2.pop();
    }
    time += 1;//时间戳加1
    timeList[a] = time;//记录该时间戳为v.f
}
```

==时间复杂度:==在DFS的遍历中我们最多经过有$O(V)$次弹栈和压栈，这对DFS原有的$\Theta(V+E)$不会产生实质性的影响。因此时间复杂度依然为$\Theta(V+E)$

​		这个算法可以正确的运行，具体不再证明，有兴趣的读者可参考原论文。这个算法来自Gabow在2000年发表的论文，如果想更深入的了解可以参考[Path-based depth-first search for strong and biconnected components](https://www.cs.princeton.edu/courses/archive/spr03/cs423/download/path_based_dfs.pdf)

## 七、应用场景

​		图是一个应用非常广泛的数据结构，成千上百的计算问题最后都会转化为图论问题，比较典型的是计算最短路径，流网络最大流，最小生成树算法等等。

## 八、如有错误或描述不当，请多多指教！不胜感激！

![2280f68d27fab5a304c9b0264903bb20](https://tva1.sinaimg.cn/large/e6c9d24egy1h16w98rteuj20u00u0ack.jpg)



​					  																																												2022年3月24日

​                                                                                                   	                                                                     weekie_OUO